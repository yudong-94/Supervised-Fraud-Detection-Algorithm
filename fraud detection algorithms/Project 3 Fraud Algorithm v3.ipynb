{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "data = pd.read_csv(\"all_data_updated.csv\", index_col = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recordnum</th>\n",
       "      <th>cardnum</th>\n",
       "      <th>date</th>\n",
       "      <th>merchnum</th>\n",
       "      <th>merch.description</th>\n",
       "      <th>merch.state</th>\n",
       "      <th>merch.zip</th>\n",
       "      <th>transtype</th>\n",
       "      <th>amount</th>\n",
       "      <th>fraud</th>\n",
       "      <th>...</th>\n",
       "      <th>merchnum_per_card_14</th>\n",
       "      <th>merchnum_per_card_28</th>\n",
       "      <th>merchant_frequency_3</th>\n",
       "      <th>merchant_frequency_7</th>\n",
       "      <th>merchant_frequency_14</th>\n",
       "      <th>merchant_frequency_28</th>\n",
       "      <th>card_frequency_3</th>\n",
       "      <th>card_frequency_7</th>\n",
       "      <th>card_frequency_14</th>\n",
       "      <th>card_frequency_28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5142190439</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>5509006296254</td>\n",
       "      <td>FEDEX SHP 12/23/09 AB#</td>\n",
       "      <td>TN</td>\n",
       "      <td>38118</td>\n",
       "      <td>P</td>\n",
       "      <td>3.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5142190439</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>5509006296254</td>\n",
       "      <td>FEDEX SHP 12/23/09 AB#</td>\n",
       "      <td>TN</td>\n",
       "      <td>38118</td>\n",
       "      <td>P</td>\n",
       "      <td>3.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5142190439</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>5509006296254</td>\n",
       "      <td>FEDEX SHP 12/23/09 AB#</td>\n",
       "      <td>TN</td>\n",
       "      <td>38118</td>\n",
       "      <td>P</td>\n",
       "      <td>3.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5142152067</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>5509006296254</td>\n",
       "      <td>FEDEX SHP 12/21/09 AB#</td>\n",
       "      <td>TN</td>\n",
       "      <td>38118</td>\n",
       "      <td>P</td>\n",
       "      <td>3.67</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5142132941</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>5509006296254</td>\n",
       "      <td>FEDEX SHP 12/27/09 AB#</td>\n",
       "      <td>TN</td>\n",
       "      <td>38118</td>\n",
       "      <td>P</td>\n",
       "      <td>3.62</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   recordnum     cardnum        date       merchnum       merch.description  \\\n",
       "1          1  5142190439  2010-01-01  5509006296254  FEDEX SHP 12/23/09 AB#   \n",
       "2          2  5142190439  2010-01-01  5509006296254  FEDEX SHP 12/23/09 AB#   \n",
       "3          3  5142190439  2010-01-01  5509006296254  FEDEX SHP 12/23/09 AB#   \n",
       "4          4  5142152067  2010-01-01  5509006296254  FEDEX SHP 12/21/09 AB#   \n",
       "5          5  5142132941  2010-01-01  5509006296254  FEDEX SHP 12/27/09 AB#   \n",
       "\n",
       "  merch.state merch.zip transtype  amount  fraud        ...          \\\n",
       "1          TN     38118         P    3.62    NaN        ...           \n",
       "2          TN     38118         P    3.62    NaN        ...           \n",
       "3          TN     38118         P    3.62    NaN        ...           \n",
       "4          TN     38118         P    3.67    NaN        ...           \n",
       "5          TN     38118         P    3.62    NaN        ...           \n",
       "\n",
       "   merchnum_per_card_14  merchnum_per_card_28  merchant_frequency_3  \\\n",
       "1                     1                     1                     1   \n",
       "2                     1                     1                     2   \n",
       "3                     1                     1                     3   \n",
       "4                     1                     1                     4   \n",
       "5                     1                     1                     5   \n",
       "\n",
       "   merchant_frequency_7  merchant_frequency_14  merchant_frequency_28  \\\n",
       "1                     1                      1                      1   \n",
       "2                     2                      2                      2   \n",
       "3                     3                      3                      3   \n",
       "4                     4                      4                      4   \n",
       "5                     5                      5                      5   \n",
       "\n",
       "   card_frequency_3  card_frequency_7  card_frequency_14  card_frequency_28  \n",
       "1                 1                 1                  1                  1  \n",
       "2                 2                 2                  2                  2  \n",
       "3                 3                 3                  3                  3  \n",
       "4                 1                 1                  1                  1  \n",
       "5                 1                 1                  1                  1  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Look at the data\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "recordnum                       False\n",
      "cardnum                         False\n",
      "date                            False\n",
      "merchnum                        False\n",
      "merch.description               False\n",
      "merch.state                     False\n",
      "merch.zip                       False\n",
      "transtype                       False\n",
      "amount                          False\n",
      "fraud                            True\n",
      "card_amount_to_avg_3            False\n",
      "card_amount_to_max_3            False\n",
      "card_amount_to_median_3         False\n",
      "card_amount_to_total_3          False\n",
      "merchant_amount_to_avg_3        False\n",
      "merchant_amount_to_max_3        False\n",
      "merchant_amount_to_median_3     False\n",
      "merchant_amount_to_total_3      False\n",
      "card_amount_to_avg_7            False\n",
      "card_amount_to_max_7            False\n",
      "card_amount_to_median_7         False\n",
      "card_amount_to_total_7          False\n",
      "merchant_amount_to_avg_7        False\n",
      "merchant_amount_to_max_7        False\n",
      "merchant_amount_to_median_7     False\n",
      "merchant_amount_to_total_7      False\n",
      "card_amount_to_avg_14           False\n",
      "card_amount_to_max_14           False\n",
      "card_amount_to_median_14        False\n",
      "card_amount_to_total_14         False\n",
      "                                ...  \n",
      "card_amount_to_median_28        False\n",
      "card_amount_to_total_28         False\n",
      "merchant_amount_to_avg_28       False\n",
      "merchant_amount_to_max_28       False\n",
      "merchant_amount_to_median_28    False\n",
      "merchant_amount_to_total_28     False\n",
      "zip_with_merchnum_3             False\n",
      "state_with_merchnum_3           False\n",
      "zip_with_merchnum_7             False\n",
      "state_with_merchnum_7           False\n",
      "cardnum_per_merch_3             False\n",
      "cardnum_per_merch_7             False\n",
      "merchnum_per_card_3             False\n",
      "merchnum_per_card_7             False\n",
      "zip_with_merchnum_14            False\n",
      "state_with_merchnum_14          False\n",
      "zip_with_merchnum_28            False\n",
      "state_with_merchnum_28          False\n",
      "cardnum_per_merch_14            False\n",
      "cardnum_per_merch_28            False\n",
      "merchnum_per_card_14            False\n",
      "merchnum_per_card_28            False\n",
      "merchant_frequency_3            False\n",
      "merchant_frequency_7            False\n",
      "merchant_frequency_14           False\n",
      "merchant_frequency_28           False\n",
      "card_frequency_3                False\n",
      "card_frequency_7                False\n",
      "card_frequency_14               False\n",
      "card_frequency_28               False\n",
      "dtype: bool\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recordnum</th>\n",
       "      <th>cardnum</th>\n",
       "      <th>date</th>\n",
       "      <th>merchnum</th>\n",
       "      <th>merch.description</th>\n",
       "      <th>merch.state</th>\n",
       "      <th>merch.zip</th>\n",
       "      <th>transtype</th>\n",
       "      <th>amount</th>\n",
       "      <th>fraud</th>\n",
       "      <th>...</th>\n",
       "      <th>merchnum_per_card_14</th>\n",
       "      <th>merchnum_per_card_28</th>\n",
       "      <th>merchant_frequency_3</th>\n",
       "      <th>merchant_frequency_7</th>\n",
       "      <th>merchant_frequency_14</th>\n",
       "      <th>merchant_frequency_28</th>\n",
       "      <th>card_frequency_3</th>\n",
       "      <th>card_frequency_7</th>\n",
       "      <th>card_frequency_14</th>\n",
       "      <th>card_frequency_28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5142190439</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>5509006296254</td>\n",
       "      <td>FEDEX SHP 12/23/09 AB#</td>\n",
       "      <td>TN</td>\n",
       "      <td>38118</td>\n",
       "      <td>P</td>\n",
       "      <td>3.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>5142190439</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>5509006296254</td>\n",
       "      <td>FEDEX SHP 12/23/09 AB#</td>\n",
       "      <td>TN</td>\n",
       "      <td>38118</td>\n",
       "      <td>P</td>\n",
       "      <td>3.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>5142190439</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>5509006296254</td>\n",
       "      <td>FEDEX SHP 12/23/09 AB#</td>\n",
       "      <td>TN</td>\n",
       "      <td>38118</td>\n",
       "      <td>P</td>\n",
       "      <td>3.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>5142152067</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>5509006296254</td>\n",
       "      <td>FEDEX SHP 12/21/09 AB#</td>\n",
       "      <td>TN</td>\n",
       "      <td>38118</td>\n",
       "      <td>P</td>\n",
       "      <td>3.67</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>5142132941</td>\n",
       "      <td>2010-01-01</td>\n",
       "      <td>5509006296254</td>\n",
       "      <td>FEDEX SHP 12/27/09 AB#</td>\n",
       "      <td>TN</td>\n",
       "      <td>38118</td>\n",
       "      <td>P</td>\n",
       "      <td>3.62</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   recordnum     cardnum        date       merchnum       merch.description  \\\n",
       "1          1  5142190439  2010-01-01  5509006296254  FEDEX SHP 12/23/09 AB#   \n",
       "2          2  5142190439  2010-01-01  5509006296254  FEDEX SHP 12/23/09 AB#   \n",
       "3          3  5142190439  2010-01-01  5509006296254  FEDEX SHP 12/23/09 AB#   \n",
       "4          4  5142152067  2010-01-01  5509006296254  FEDEX SHP 12/21/09 AB#   \n",
       "5          5  5142132941  2010-01-01  5509006296254  FEDEX SHP 12/27/09 AB#   \n",
       "\n",
       "  merch.state merch.zip transtype  amount  fraud        ...          \\\n",
       "1          TN     38118         P    3.62    0.0        ...           \n",
       "2          TN     38118         P    3.62    0.0        ...           \n",
       "3          TN     38118         P    3.62    0.0        ...           \n",
       "4          TN     38118         P    3.67    0.0        ...           \n",
       "5          TN     38118         P    3.62    0.0        ...           \n",
       "\n",
       "   merchnum_per_card_14  merchnum_per_card_28  merchant_frequency_3  \\\n",
       "1                     1                     1                     1   \n",
       "2                     1                     1                     2   \n",
       "3                     1                     1                     3   \n",
       "4                     1                     1                     4   \n",
       "5                     1                     1                     5   \n",
       "\n",
       "   merchant_frequency_7  merchant_frequency_14  merchant_frequency_28  \\\n",
       "1                     1                      1                      1   \n",
       "2                     2                      2                      2   \n",
       "3                     3                      3                      3   \n",
       "4                     4                      4                      4   \n",
       "5                     5                      5                      5   \n",
       "\n",
       "   card_frequency_3  card_frequency_7  card_frequency_14  card_frequency_28  \n",
       "1                 1                 1                  1                  1  \n",
       "2                 2                 2                  2                  2  \n",
       "3                 3                 3                  3                  3  \n",
       "4                 1                 1                  1                  1  \n",
       "5                 1                 1                  1                  1  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# test for NAN\n",
    "print pd.isnull(data).any()\n",
    "# fill NAN with 0 in \"fraud\" column\n",
    "data = data.fillna(0)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(88621, 57)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fraud</th>\n",
       "      <th>card_amount_to_avg_3</th>\n",
       "      <th>card_amount_to_max_3</th>\n",
       "      <th>card_amount_to_median_3</th>\n",
       "      <th>card_amount_to_total_3</th>\n",
       "      <th>merchant_amount_to_avg_3</th>\n",
       "      <th>merchant_amount_to_max_3</th>\n",
       "      <th>merchant_amount_to_median_3</th>\n",
       "      <th>merchant_amount_to_total_3</th>\n",
       "      <th>card_amount_to_avg_7</th>\n",
       "      <th>...</th>\n",
       "      <th>merchnum_per_card_14</th>\n",
       "      <th>merchnum_per_card_28</th>\n",
       "      <th>merchant_frequency_3</th>\n",
       "      <th>merchant_frequency_7</th>\n",
       "      <th>merchant_frequency_14</th>\n",
       "      <th>merchant_frequency_28</th>\n",
       "      <th>card_frequency_3</th>\n",
       "      <th>card_frequency_7</th>\n",
       "      <th>card_frequency_14</th>\n",
       "      <th>card_frequency_28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6387</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.667055</td>\n",
       "      <td>0.667055</td>\n",
       "      <td>0.667055</td>\n",
       "      <td>0.667055</td>\n",
       "      <td>0.065900</td>\n",
       "      <td>0.065900</td>\n",
       "      <td>0.065900</td>\n",
       "      <td>0.065900</td>\n",
       "      <td>0.667055</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6388</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.050678</td>\n",
       "      <td>0.050678</td>\n",
       "      <td>0.050678</td>\n",
       "      <td>0.050678</td>\n",
       "      <td>0.535842</td>\n",
       "      <td>0.535842</td>\n",
       "      <td>0.535842</td>\n",
       "      <td>0.535842</td>\n",
       "      <td>0.038454</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6389</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.743966</td>\n",
       "      <td>2.065000</td>\n",
       "      <td>3.743966</td>\n",
       "      <td>1.871983</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.807755</td>\n",
       "      <td>...</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6390</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.740060</td>\n",
       "      <td>0.456971</td>\n",
       "      <td>0.740060</td>\n",
       "      <td>0.370030</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.103021</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6391</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.192225</td>\n",
       "      <td>0.192225</td>\n",
       "      <td>0.192225</td>\n",
       "      <td>0.192225</td>\n",
       "      <td>0.230989</td>\n",
       "      <td>0.069375</td>\n",
       "      <td>0.324845</td>\n",
       "      <td>0.015399</td>\n",
       "      <td>0.192225</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>16</td>\n",
       "      <td>22</td>\n",
       "      <td>37</td>\n",
       "      <td>68</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fraud  card_amount_to_avg_3  card_amount_to_max_3  \\\n",
       "6387    0.0              0.667055              0.667055   \n",
       "6388    0.0              0.050678              0.050678   \n",
       "6389    0.0              3.743966              2.065000   \n",
       "6390    0.0              0.740060              0.456971   \n",
       "6391    0.0              0.192225              0.192225   \n",
       "\n",
       "      card_amount_to_median_3  card_amount_to_total_3  \\\n",
       "6387                 0.667055                0.667055   \n",
       "6388                 0.050678                0.050678   \n",
       "6389                 3.743966                1.871983   \n",
       "6390                 0.740060                0.370030   \n",
       "6391                 0.192225                0.192225   \n",
       "\n",
       "      merchant_amount_to_avg_3  merchant_amount_to_max_3  \\\n",
       "6387                  0.065900                  0.065900   \n",
       "6388                  0.535842                  0.535842   \n",
       "6389                  1.000000                  0.000000   \n",
       "6390                  1.000000                  0.000000   \n",
       "6391                  0.230989                  0.069375   \n",
       "\n",
       "      merchant_amount_to_median_3  merchant_amount_to_total_3  \\\n",
       "6387                     0.065900                    0.065900   \n",
       "6388                     0.535842                    0.535842   \n",
       "6389                     1.000000                    0.000000   \n",
       "6390                     1.000000                    0.000000   \n",
       "6391                     0.324845                    0.015399   \n",
       "\n",
       "      card_amount_to_avg_7        ...          merchnum_per_card_14  \\\n",
       "6387              0.667055        ...                             2   \n",
       "6388              0.038454        ...                             3   \n",
       "6389              6.807755        ...                             8   \n",
       "6390              1.103021        ...                             3   \n",
       "6391              0.192225        ...                             4   \n",
       "\n",
       "      merchnum_per_card_28  merchant_frequency_3  merchant_frequency_7  \\\n",
       "6387                     2                     2                     2   \n",
       "6388                     6                     2                     2   \n",
       "6389                    10                     1                     1   \n",
       "6390                     5                     1                     1   \n",
       "6391                     8                    16                    22   \n",
       "\n",
       "      merchant_frequency_14  merchant_frequency_28  card_frequency_3  \\\n",
       "6387                      2                      3                 2   \n",
       "6388                      2                      2                 2   \n",
       "6389                      1                      1                 3   \n",
       "6390                      1                      1                 3   \n",
       "6391                     37                     68                 2   \n",
       "\n",
       "      card_frequency_7  card_frequency_14  card_frequency_28  \n",
       "6387                 2                  3                  3  \n",
       "6388                 4                  5                  8  \n",
       "6389                 7                 13                 15  \n",
       "6390                 4                  4                  7  \n",
       "6391                 2                  7                 13  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# only keep the data after 28 days\n",
    "df = data[data[\"date\"]>\"2010-01-28\"]\n",
    "# only extract the label and features columns\n",
    "df = df.iloc[:,9:]\n",
    "print df.shape\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "295.0\n",
      "88621\n",
      "0.00332878211711\n"
     ]
    }
   ],
   "source": [
    "# split lables and features\n",
    "labels = df[\"fraud\"]\n",
    "features = df.iloc[:,1:]\n",
    "\n",
    "print sum(labels)\n",
    "print len(labels)\n",
    "print sum(labels)/len(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import neccessary sklearn packages\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.feature_selection import mutual_info_classif\n",
    "from sklearn.utils import resample\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.base import clone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# pre-process dataset with z-scaling\n",
    "df[df.columns[1:]] = scale(df[df.columns[1:]])\n",
    "features = scale(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fraud</th>\n",
       "      <th>card_amount_to_avg_3</th>\n",
       "      <th>card_amount_to_max_3</th>\n",
       "      <th>card_amount_to_median_3</th>\n",
       "      <th>card_amount_to_total_3</th>\n",
       "      <th>merchant_amount_to_avg_3</th>\n",
       "      <th>merchant_amount_to_max_3</th>\n",
       "      <th>merchant_amount_to_median_3</th>\n",
       "      <th>merchant_amount_to_total_3</th>\n",
       "      <th>card_amount_to_avg_7</th>\n",
       "      <th>...</th>\n",
       "      <th>merchnum_per_card_14</th>\n",
       "      <th>merchnum_per_card_28</th>\n",
       "      <th>merchant_frequency_3</th>\n",
       "      <th>merchant_frequency_7</th>\n",
       "      <th>merchant_frequency_14</th>\n",
       "      <th>merchant_frequency_28</th>\n",
       "      <th>card_frequency_3</th>\n",
       "      <th>card_frequency_7</th>\n",
       "      <th>card_frequency_14</th>\n",
       "      <th>card_frequency_28</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6387</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.069713</td>\n",
       "      <td>-0.048956</td>\n",
       "      <td>-0.091941</td>\n",
       "      <td>-0.038273</td>\n",
       "      <td>-0.201987</td>\n",
       "      <td>-0.094556</td>\n",
       "      <td>-0.220692</td>\n",
       "      <td>-0.077500</td>\n",
       "      <td>-0.059868</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.618471</td>\n",
       "      <td>-0.788860</td>\n",
       "      <td>-0.343639</td>\n",
       "      <td>-0.379143</td>\n",
       "      <td>-0.388146</td>\n",
       "      <td>-0.387467</td>\n",
       "      <td>-0.236040</td>\n",
       "      <td>-0.333167</td>\n",
       "      <td>-0.432163</td>\n",
       "      <td>-0.560908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6388</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.087416</td>\n",
       "      <td>-0.066921</td>\n",
       "      <td>-0.108029</td>\n",
       "      <td>-0.057062</td>\n",
       "      <td>-0.133731</td>\n",
       "      <td>-0.022105</td>\n",
       "      <td>-0.162222</td>\n",
       "      <td>-0.002350</td>\n",
       "      <td>-0.078011</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.418964</td>\n",
       "      <td>-0.294452</td>\n",
       "      <td>-0.343639</td>\n",
       "      <td>-0.379143</td>\n",
       "      <td>-0.388146</td>\n",
       "      <td>-0.390234</td>\n",
       "      <td>-0.236040</td>\n",
       "      <td>-0.213197</td>\n",
       "      <td>-0.333148</td>\n",
       "      <td>-0.392973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6389</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018664</td>\n",
       "      <td>-0.008213</td>\n",
       "      <td>-0.011633</td>\n",
       "      <td>-0.001544</td>\n",
       "      <td>-0.066316</td>\n",
       "      <td>-0.104716</td>\n",
       "      <td>-0.104471</td>\n",
       "      <td>-0.088039</td>\n",
       "      <td>0.117367</td>\n",
       "      <td>...</td>\n",
       "      <td>0.578570</td>\n",
       "      <td>0.199956</td>\n",
       "      <td>-0.361488</td>\n",
       "      <td>-0.388420</td>\n",
       "      <td>-0.393272</td>\n",
       "      <td>-0.393002</td>\n",
       "      <td>-0.150046</td>\n",
       "      <td>-0.033244</td>\n",
       "      <td>0.062912</td>\n",
       "      <td>-0.157863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6390</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.067616</td>\n",
       "      <td>-0.055079</td>\n",
       "      <td>-0.090036</td>\n",
       "      <td>-0.047327</td>\n",
       "      <td>-0.066316</td>\n",
       "      <td>-0.104716</td>\n",
       "      <td>-0.104471</td>\n",
       "      <td>-0.088039</td>\n",
       "      <td>-0.047285</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.418964</td>\n",
       "      <td>-0.418054</td>\n",
       "      <td>-0.361488</td>\n",
       "      <td>-0.388420</td>\n",
       "      <td>-0.393272</td>\n",
       "      <td>-0.393002</td>\n",
       "      <td>-0.150046</td>\n",
       "      <td>-0.213197</td>\n",
       "      <td>-0.382656</td>\n",
       "      <td>-0.426560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6391</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.083351</td>\n",
       "      <td>-0.062795</td>\n",
       "      <td>-0.104334</td>\n",
       "      <td>-0.052747</td>\n",
       "      <td>-0.178009</td>\n",
       "      <td>-0.094020</td>\n",
       "      <td>-0.188474</td>\n",
       "      <td>-0.085576</td>\n",
       "      <td>-0.073573</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.219457</td>\n",
       "      <td>-0.047248</td>\n",
       "      <td>-0.093762</td>\n",
       "      <td>-0.193618</td>\n",
       "      <td>-0.208743</td>\n",
       "      <td>-0.207576</td>\n",
       "      <td>-0.236040</td>\n",
       "      <td>-0.333167</td>\n",
       "      <td>-0.234133</td>\n",
       "      <td>-0.225037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6392</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.071883</td>\n",
       "      <td>-0.056158</td>\n",
       "      <td>-0.093913</td>\n",
       "      <td>-0.049592</td>\n",
       "      <td>-0.117387</td>\n",
       "      <td>-0.094627</td>\n",
       "      <td>-0.106166</td>\n",
       "      <td>-0.086819</td>\n",
       "      <td>-0.056506</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.817978</td>\n",
       "      <td>-0.788860</td>\n",
       "      <td>1.155626</td>\n",
       "      <td>2.004854</td>\n",
       "      <td>1.856948</td>\n",
       "      <td>1.660517</td>\n",
       "      <td>-0.150046</td>\n",
       "      <td>-0.093228</td>\n",
       "      <td>-0.234133</td>\n",
       "      <td>-0.292212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6393</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.069205</td>\n",
       "      <td>-0.056158</td>\n",
       "      <td>-0.083251</td>\n",
       "      <td>-0.051649</td>\n",
       "      <td>-0.117000</td>\n",
       "      <td>-0.094627</td>\n",
       "      <td>-0.105324</td>\n",
       "      <td>-0.086828</td>\n",
       "      <td>-0.055660</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.817978</td>\n",
       "      <td>-0.788860</td>\n",
       "      <td>1.173474</td>\n",
       "      <td>2.014130</td>\n",
       "      <td>1.862074</td>\n",
       "      <td>1.663285</td>\n",
       "      <td>-0.064052</td>\n",
       "      <td>-0.033244</td>\n",
       "      <td>-0.184626</td>\n",
       "      <td>-0.258624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6394</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.060150</td>\n",
       "      <td>-0.068398</td>\n",
       "      <td>-0.083251</td>\n",
       "      <td>-0.058607</td>\n",
       "      <td>-0.113472</td>\n",
       "      <td>-0.094293</td>\n",
       "      <td>-0.100346</td>\n",
       "      <td>-0.086798</td>\n",
       "      <td>-0.069245</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.618471</td>\n",
       "      <td>-0.418054</td>\n",
       "      <td>1.191323</td>\n",
       "      <td>2.023406</td>\n",
       "      <td>1.867200</td>\n",
       "      <td>1.666052</td>\n",
       "      <td>-0.322034</td>\n",
       "      <td>-0.033244</td>\n",
       "      <td>-0.085611</td>\n",
       "      <td>-0.191450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6395</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.078011</td>\n",
       "      <td>-0.057377</td>\n",
       "      <td>-0.099482</td>\n",
       "      <td>-0.047081</td>\n",
       "      <td>-0.066316</td>\n",
       "      <td>-0.104716</td>\n",
       "      <td>-0.104471</td>\n",
       "      <td>-0.088039</td>\n",
       "      <td>-0.068208</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.817978</td>\n",
       "      <td>-0.541656</td>\n",
       "      <td>-0.361488</td>\n",
       "      <td>-0.379143</td>\n",
       "      <td>-0.388146</td>\n",
       "      <td>-0.390234</td>\n",
       "      <td>-0.236040</td>\n",
       "      <td>-0.333167</td>\n",
       "      <td>-0.481671</td>\n",
       "      <td>-0.460147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6396</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.060150</td>\n",
       "      <td>-0.068398</td>\n",
       "      <td>-0.083251</td>\n",
       "      <td>-0.058607</td>\n",
       "      <td>0.189849</td>\n",
       "      <td>0.321364</td>\n",
       "      <td>0.114972</td>\n",
       "      <td>0.353919</td>\n",
       "      <td>-0.050259</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.618471</td>\n",
       "      <td>-0.170850</td>\n",
       "      <td>-0.343639</td>\n",
       "      <td>-0.379143</td>\n",
       "      <td>-0.383020</td>\n",
       "      <td>-0.384699</td>\n",
       "      <td>-0.322034</td>\n",
       "      <td>-0.393151</td>\n",
       "      <td>-0.432163</td>\n",
       "      <td>-0.359386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6397</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.060150</td>\n",
       "      <td>-0.068398</td>\n",
       "      <td>-0.083251</td>\n",
       "      <td>-0.058607</td>\n",
       "      <td>-0.188953</td>\n",
       "      <td>-0.080721</td>\n",
       "      <td>-0.209527</td>\n",
       "      <td>-0.063150</td>\n",
       "      <td>0.427385</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.418964</td>\n",
       "      <td>-0.418054</td>\n",
       "      <td>-0.343639</td>\n",
       "      <td>-0.369867</td>\n",
       "      <td>-0.367643</td>\n",
       "      <td>-0.354256</td>\n",
       "      <td>-0.322034</td>\n",
       "      <td>-0.273182</td>\n",
       "      <td>-0.283641</td>\n",
       "      <td>-0.392973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6398</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.049298</td>\n",
       "      <td>-0.039252</td>\n",
       "      <td>-0.077698</td>\n",
       "      <td>-0.048107</td>\n",
       "      <td>0.163550</td>\n",
       "      <td>-0.065003</td>\n",
       "      <td>0.257528</td>\n",
       "      <td>-0.083346</td>\n",
       "      <td>-0.045780</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.817978</td>\n",
       "      <td>-0.912462</td>\n",
       "      <td>1.209171</td>\n",
       "      <td>2.032682</td>\n",
       "      <td>1.872325</td>\n",
       "      <td>1.668820</td>\n",
       "      <td>0.021942</td>\n",
       "      <td>0.626587</td>\n",
       "      <td>0.508479</td>\n",
       "      <td>0.178008</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6399</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.055951</td>\n",
       "      <td>-0.042320</td>\n",
       "      <td>-0.081030</td>\n",
       "      <td>-0.051619</td>\n",
       "      <td>0.118201</td>\n",
       "      <td>-0.069183</td>\n",
       "      <td>0.203361</td>\n",
       "      <td>-0.083959</td>\n",
       "      <td>-0.049545</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.817978</td>\n",
       "      <td>-0.912462</td>\n",
       "      <td>1.227020</td>\n",
       "      <td>2.041959</td>\n",
       "      <td>1.877451</td>\n",
       "      <td>1.671587</td>\n",
       "      <td>0.107936</td>\n",
       "      <td>0.686571</td>\n",
       "      <td>0.557986</td>\n",
       "      <td>0.211595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6400</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.059255</td>\n",
       "      <td>-0.044366</td>\n",
       "      <td>-0.084317</td>\n",
       "      <td>-0.053368</td>\n",
       "      <td>0.088107</td>\n",
       "      <td>-0.071970</td>\n",
       "      <td>0.169459</td>\n",
       "      <td>-0.084373</td>\n",
       "      <td>-0.051900</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.817978</td>\n",
       "      <td>-0.912462</td>\n",
       "      <td>1.244868</td>\n",
       "      <td>2.051235</td>\n",
       "      <td>1.882577</td>\n",
       "      <td>1.674355</td>\n",
       "      <td>0.193930</td>\n",
       "      <td>0.746556</td>\n",
       "      <td>0.607494</td>\n",
       "      <td>0.245182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6401</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.061895</td>\n",
       "      <td>-0.046411</td>\n",
       "      <td>-0.085473</td>\n",
       "      <td>-0.054517</td>\n",
       "      <td>0.059438</td>\n",
       "      <td>-0.074757</td>\n",
       "      <td>0.135557</td>\n",
       "      <td>-0.084760</td>\n",
       "      <td>-0.054146</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.817978</td>\n",
       "      <td>-0.912462</td>\n",
       "      <td>1.262716</td>\n",
       "      <td>2.060511</td>\n",
       "      <td>1.887703</td>\n",
       "      <td>1.677123</td>\n",
       "      <td>0.279924</td>\n",
       "      <td>0.806541</td>\n",
       "      <td>0.657001</td>\n",
       "      <td>0.278769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6402</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.079263</td>\n",
       "      <td>-0.060626</td>\n",
       "      <td>-0.100911</td>\n",
       "      <td>-0.057332</td>\n",
       "      <td>-0.116658</td>\n",
       "      <td>-0.094126</td>\n",
       "      <td>-0.100063</td>\n",
       "      <td>-0.086903</td>\n",
       "      <td>-0.070236</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.817978</td>\n",
       "      <td>-0.912462</td>\n",
       "      <td>1.280565</td>\n",
       "      <td>2.069787</td>\n",
       "      <td>1.892828</td>\n",
       "      <td>1.679890</td>\n",
       "      <td>0.365918</td>\n",
       "      <td>0.866525</td>\n",
       "      <td>0.706509</td>\n",
       "      <td>0.312356</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6403</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.078496</td>\n",
       "      <td>-0.060626</td>\n",
       "      <td>-0.100911</td>\n",
       "      <td>-0.057383</td>\n",
       "      <td>-0.116303</td>\n",
       "      <td>-0.094126</td>\n",
       "      <td>-0.100063</td>\n",
       "      <td>-0.086911</td>\n",
       "      <td>-0.069947</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.817978</td>\n",
       "      <td>-0.912462</td>\n",
       "      <td>1.298413</td>\n",
       "      <td>2.079064</td>\n",
       "      <td>1.897954</td>\n",
       "      <td>1.682658</td>\n",
       "      <td>0.451912</td>\n",
       "      <td>0.926510</td>\n",
       "      <td>0.756016</td>\n",
       "      <td>0.345943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6404</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.077788</td>\n",
       "      <td>-0.060626</td>\n",
       "      <td>-0.100911</td>\n",
       "      <td>-0.057430</td>\n",
       "      <td>-0.115953</td>\n",
       "      <td>-0.094126</td>\n",
       "      <td>-0.101280</td>\n",
       "      <td>-0.086919</td>\n",
       "      <td>-0.069667</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.817978</td>\n",
       "      <td>-0.912462</td>\n",
       "      <td>1.316262</td>\n",
       "      <td>2.088340</td>\n",
       "      <td>1.903080</td>\n",
       "      <td>1.685425</td>\n",
       "      <td>0.537906</td>\n",
       "      <td>0.986494</td>\n",
       "      <td>0.805524</td>\n",
       "      <td>0.379530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6405</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.077689</td>\n",
       "      <td>-0.060994</td>\n",
       "      <td>-0.101310</td>\n",
       "      <td>-0.057528</td>\n",
       "      <td>-0.120152</td>\n",
       "      <td>-0.094627</td>\n",
       "      <td>-0.108463</td>\n",
       "      <td>-0.086979</td>\n",
       "      <td>-0.069855</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.817978</td>\n",
       "      <td>-0.912462</td>\n",
       "      <td>1.334110</td>\n",
       "      <td>2.097616</td>\n",
       "      <td>1.908206</td>\n",
       "      <td>1.688193</td>\n",
       "      <td>0.623900</td>\n",
       "      <td>1.046479</td>\n",
       "      <td>0.855031</td>\n",
       "      <td>0.413117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6406</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.077089</td>\n",
       "      <td>-0.060994</td>\n",
       "      <td>-0.100953</td>\n",
       "      <td>-0.057565</td>\n",
       "      <td>-0.119798</td>\n",
       "      <td>-0.094627</td>\n",
       "      <td>-0.107325</td>\n",
       "      <td>-0.086986</td>\n",
       "      <td>-0.069596</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.817978</td>\n",
       "      <td>-0.912462</td>\n",
       "      <td>1.351958</td>\n",
       "      <td>2.106892</td>\n",
       "      <td>1.913332</td>\n",
       "      <td>1.690960</td>\n",
       "      <td>0.709894</td>\n",
       "      <td>1.106463</td>\n",
       "      <td>0.904538</td>\n",
       "      <td>0.446704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6407</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.076529</td>\n",
       "      <td>-0.060994</td>\n",
       "      <td>-0.100562</td>\n",
       "      <td>-0.057599</td>\n",
       "      <td>-0.119448</td>\n",
       "      <td>-0.094627</td>\n",
       "      <td>-0.106166</td>\n",
       "      <td>-0.086993</td>\n",
       "      <td>-0.069344</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.817978</td>\n",
       "      <td>-0.912462</td>\n",
       "      <td>1.369807</td>\n",
       "      <td>2.116169</td>\n",
       "      <td>1.918457</td>\n",
       "      <td>1.693728</td>\n",
       "      <td>0.795888</td>\n",
       "      <td>1.166448</td>\n",
       "      <td>0.954046</td>\n",
       "      <td>0.480291</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6408</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.056535</td>\n",
       "      <td>-0.035584</td>\n",
       "      <td>-0.079966</td>\n",
       "      <td>-0.024288</td>\n",
       "      <td>-0.158190</td>\n",
       "      <td>-0.078758</td>\n",
       "      <td>-0.169368</td>\n",
       "      <td>-0.078246</td>\n",
       "      <td>-0.056671</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.418964</td>\n",
       "      <td>-0.047248</td>\n",
       "      <td>-0.254397</td>\n",
       "      <td>-0.323486</td>\n",
       "      <td>-0.306133</td>\n",
       "      <td>-0.307208</td>\n",
       "      <td>-0.236040</td>\n",
       "      <td>-0.273182</td>\n",
       "      <td>-0.382656</td>\n",
       "      <td>-0.225037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6409</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.060150</td>\n",
       "      <td>-0.068398</td>\n",
       "      <td>-0.083251</td>\n",
       "      <td>-0.058607</td>\n",
       "      <td>-0.093920</td>\n",
       "      <td>-0.069015</td>\n",
       "      <td>-0.093982</td>\n",
       "      <td>-0.079944</td>\n",
       "      <td>-0.050259</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.618471</td>\n",
       "      <td>0.076354</td>\n",
       "      <td>-0.075913</td>\n",
       "      <td>-0.184342</td>\n",
       "      <td>-0.203618</td>\n",
       "      <td>-0.204809</td>\n",
       "      <td>-0.322034</td>\n",
       "      <td>-0.393151</td>\n",
       "      <td>-0.432163</td>\n",
       "      <td>-0.225037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6410</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.075764</td>\n",
       "      <td>-0.063865</td>\n",
       "      <td>-0.094279</td>\n",
       "      <td>-0.055825</td>\n",
       "      <td>-0.066316</td>\n",
       "      <td>-0.104716</td>\n",
       "      <td>-0.104471</td>\n",
       "      <td>-0.088039</td>\n",
       "      <td>-0.059364</td>\n",
       "      <td>...</td>\n",
       "      <td>0.578570</td>\n",
       "      <td>0.447160</td>\n",
       "      <td>-0.361488</td>\n",
       "      <td>-0.388420</td>\n",
       "      <td>-0.388146</td>\n",
       "      <td>-0.384699</td>\n",
       "      <td>0.107936</td>\n",
       "      <td>0.086726</td>\n",
       "      <td>0.013404</td>\n",
       "      <td>0.043659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6411</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.086931</td>\n",
       "      <td>-0.066428</td>\n",
       "      <td>-0.107588</td>\n",
       "      <td>-0.056547</td>\n",
       "      <td>-0.136226</td>\n",
       "      <td>-0.075530</td>\n",
       "      <td>-0.123136</td>\n",
       "      <td>-0.067303</td>\n",
       "      <td>-0.077171</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019950</td>\n",
       "      <td>0.076354</td>\n",
       "      <td>-0.290094</td>\n",
       "      <td>-0.295657</td>\n",
       "      <td>-0.275379</td>\n",
       "      <td>-0.285067</td>\n",
       "      <td>-0.236040</td>\n",
       "      <td>-0.333167</td>\n",
       "      <td>-0.135118</td>\n",
       "      <td>-0.157863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6412</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.060150</td>\n",
       "      <td>-0.068398</td>\n",
       "      <td>-0.083251</td>\n",
       "      <td>-0.058607</td>\n",
       "      <td>0.730359</td>\n",
       "      <td>-0.001936</td>\n",
       "      <td>1.021421</td>\n",
       "      <td>-0.077457</td>\n",
       "      <td>-0.068270</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019950</td>\n",
       "      <td>0.323558</td>\n",
       "      <td>1.387655</td>\n",
       "      <td>2.125445</td>\n",
       "      <td>1.923583</td>\n",
       "      <td>1.696495</td>\n",
       "      <td>-0.322034</td>\n",
       "      <td>0.206695</td>\n",
       "      <td>0.260941</td>\n",
       "      <td>0.211595</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6413</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.086014</td>\n",
       "      <td>-0.065497</td>\n",
       "      <td>-0.106754</td>\n",
       "      <td>-0.055573</td>\n",
       "      <td>-0.122747</td>\n",
       "      <td>-0.094488</td>\n",
       "      <td>-0.104471</td>\n",
       "      <td>-0.087051</td>\n",
       "      <td>-0.077976</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019950</td>\n",
       "      <td>0.323558</td>\n",
       "      <td>1.405504</td>\n",
       "      <td>2.134721</td>\n",
       "      <td>1.928709</td>\n",
       "      <td>1.699263</td>\n",
       "      <td>-0.236040</td>\n",
       "      <td>0.266679</td>\n",
       "      <td>0.310449</td>\n",
       "      <td>0.245182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6414</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.060150</td>\n",
       "      <td>-0.068398</td>\n",
       "      <td>-0.083251</td>\n",
       "      <td>-0.058607</td>\n",
       "      <td>0.045237</td>\n",
       "      <td>0.167863</td>\n",
       "      <td>-0.008909</td>\n",
       "      <td>0.194698</td>\n",
       "      <td>-0.050259</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.817978</td>\n",
       "      <td>-0.788860</td>\n",
       "      <td>-0.343639</td>\n",
       "      <td>-0.379143</td>\n",
       "      <td>-0.377894</td>\n",
       "      <td>-0.370861</td>\n",
       "      <td>-0.322034</td>\n",
       "      <td>-0.393151</td>\n",
       "      <td>-0.531178</td>\n",
       "      <td>-0.560908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6415</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.072763</td>\n",
       "      <td>0.027008</td>\n",
       "      <td>0.009272</td>\n",
       "      <td>-0.001427</td>\n",
       "      <td>0.448557</td>\n",
       "      <td>0.595973</td>\n",
       "      <td>0.336594</td>\n",
       "      <td>0.638762</td>\n",
       "      <td>-0.031712</td>\n",
       "      <td>...</td>\n",
       "      <td>1.775611</td>\n",
       "      <td>1.312375</td>\n",
       "      <td>-0.343639</td>\n",
       "      <td>-0.379143</td>\n",
       "      <td>-0.383020</td>\n",
       "      <td>-0.387467</td>\n",
       "      <td>-0.064052</td>\n",
       "      <td>0.266679</td>\n",
       "      <td>0.409464</td>\n",
       "      <td>0.413117</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6416</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.088577</td>\n",
       "      <td>-0.068283</td>\n",
       "      <td>-0.108960</td>\n",
       "      <td>-0.058528</td>\n",
       "      <td>-0.120700</td>\n",
       "      <td>-0.094293</td>\n",
       "      <td>-0.102097</td>\n",
       "      <td>-0.087038</td>\n",
       "      <td>-0.078944</td>\n",
       "      <td>...</td>\n",
       "      <td>1.775611</td>\n",
       "      <td>1.312375</td>\n",
       "      <td>1.423352</td>\n",
       "      <td>2.143997</td>\n",
       "      <td>1.933835</td>\n",
       "      <td>1.702030</td>\n",
       "      <td>0.021942</td>\n",
       "      <td>0.326664</td>\n",
       "      <td>0.458971</td>\n",
       "      <td>0.446704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94978</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.098444</td>\n",
       "      <td>0.040782</td>\n",
       "      <td>0.060863</td>\n",
       "      <td>0.040790</td>\n",
       "      <td>0.171832</td>\n",
       "      <td>0.025746</td>\n",
       "      <td>0.533422</td>\n",
       "      <td>0.017491</td>\n",
       "      <td>0.109107</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.418964</td>\n",
       "      <td>-0.665258</td>\n",
       "      <td>-0.290094</td>\n",
       "      <td>-0.295657</td>\n",
       "      <td>-0.265127</td>\n",
       "      <td>-0.240787</td>\n",
       "      <td>-0.150046</td>\n",
       "      <td>-0.273182</td>\n",
       "      <td>-0.333148</td>\n",
       "      <td>-0.493734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94979</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.062552</td>\n",
       "      <td>-0.056765</td>\n",
       "      <td>-0.070329</td>\n",
       "      <td>-0.049296</td>\n",
       "      <td>-0.096327</td>\n",
       "      <td>-0.052646</td>\n",
       "      <td>0.003178</td>\n",
       "      <td>-0.062665</td>\n",
       "      <td>-0.052673</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.219457</td>\n",
       "      <td>-0.541656</td>\n",
       "      <td>-0.272246</td>\n",
       "      <td>-0.286381</td>\n",
       "      <td>-0.260001</td>\n",
       "      <td>-0.238019</td>\n",
       "      <td>-0.064052</td>\n",
       "      <td>-0.213197</td>\n",
       "      <td>-0.283641</td>\n",
       "      <td>-0.460147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94980</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.073711</td>\n",
       "      <td>-0.061837</td>\n",
       "      <td>-0.091710</td>\n",
       "      <td>-0.054584</td>\n",
       "      <td>-0.144250</td>\n",
       "      <td>-0.075348</td>\n",
       "      <td>-0.137527</td>\n",
       "      <td>-0.075687</td>\n",
       "      <td>-0.063886</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.219457</td>\n",
       "      <td>-0.541656</td>\n",
       "      <td>-0.254397</td>\n",
       "      <td>-0.277105</td>\n",
       "      <td>-0.254876</td>\n",
       "      <td>-0.235252</td>\n",
       "      <td>0.021942</td>\n",
       "      <td>-0.153213</td>\n",
       "      <td>-0.234133</td>\n",
       "      <td>-0.426560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94981</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.063610</td>\n",
       "      <td>-0.054890</td>\n",
       "      <td>-0.086057</td>\n",
       "      <td>-0.049670</td>\n",
       "      <td>0.173478</td>\n",
       "      <td>0.188512</td>\n",
       "      <td>0.010783</td>\n",
       "      <td>0.053272</td>\n",
       "      <td>-0.053736</td>\n",
       "      <td>...</td>\n",
       "      <td>0.379063</td>\n",
       "      <td>-0.047248</td>\n",
       "      <td>-0.307942</td>\n",
       "      <td>-0.351315</td>\n",
       "      <td>-0.311259</td>\n",
       "      <td>-0.240787</td>\n",
       "      <td>-0.064052</td>\n",
       "      <td>-0.213197</td>\n",
       "      <td>0.013404</td>\n",
       "      <td>-0.157863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94982</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.084357</td>\n",
       "      <td>-0.066056</td>\n",
       "      <td>-0.105084</td>\n",
       "      <td>-0.057409</td>\n",
       "      <td>-0.066316</td>\n",
       "      <td>-0.104716</td>\n",
       "      <td>-0.104471</td>\n",
       "      <td>-0.088039</td>\n",
       "      <td>-0.074584</td>\n",
       "      <td>...</td>\n",
       "      <td>0.379063</td>\n",
       "      <td>-0.047248</td>\n",
       "      <td>-0.361488</td>\n",
       "      <td>-0.388420</td>\n",
       "      <td>-0.372769</td>\n",
       "      <td>-0.376397</td>\n",
       "      <td>0.021942</td>\n",
       "      <td>-0.153213</td>\n",
       "      <td>0.062912</td>\n",
       "      <td>-0.124276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94983</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.057380</td>\n",
       "      <td>-0.058455</td>\n",
       "      <td>-0.021172</td>\n",
       "      <td>-0.050251</td>\n",
       "      <td>-0.066316</td>\n",
       "      <td>-0.104716</td>\n",
       "      <td>-0.104471</td>\n",
       "      <td>-0.088039</td>\n",
       "      <td>-0.055430</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.418964</td>\n",
       "      <td>-0.047248</td>\n",
       "      <td>-0.361488</td>\n",
       "      <td>-0.369867</td>\n",
       "      <td>-0.377894</td>\n",
       "      <td>-0.368094</td>\n",
       "      <td>0.021942</td>\n",
       "      <td>-0.093228</td>\n",
       "      <td>-0.283641</td>\n",
       "      <td>-0.225037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94984</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.087405</td>\n",
       "      <td>-0.067784</td>\n",
       "      <td>-0.106695</td>\n",
       "      <td>-0.058088</td>\n",
       "      <td>-0.193085</td>\n",
       "      <td>-0.099197</td>\n",
       "      <td>-0.202799</td>\n",
       "      <td>-0.085133</td>\n",
       "      <td>-0.077219</td>\n",
       "      <td>...</td>\n",
       "      <td>0.179556</td>\n",
       "      <td>0.941569</td>\n",
       "      <td>-0.236549</td>\n",
       "      <td>-0.286381</td>\n",
       "      <td>-0.193366</td>\n",
       "      <td>-0.188203</td>\n",
       "      <td>-0.064052</td>\n",
       "      <td>-0.153213</td>\n",
       "      <td>-0.234133</td>\n",
       "      <td>0.010072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94985</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.078969</td>\n",
       "      <td>-0.065238</td>\n",
       "      <td>-0.085440</td>\n",
       "      <td>-0.055979</td>\n",
       "      <td>-0.066316</td>\n",
       "      <td>-0.104716</td>\n",
       "      <td>-0.104471</td>\n",
       "      <td>-0.088039</td>\n",
       "      <td>-0.067075</td>\n",
       "      <td>...</td>\n",
       "      <td>0.179556</td>\n",
       "      <td>0.941569</td>\n",
       "      <td>-0.361488</td>\n",
       "      <td>-0.388420</td>\n",
       "      <td>-0.388146</td>\n",
       "      <td>-0.390234</td>\n",
       "      <td>0.021942</td>\n",
       "      <td>-0.093228</td>\n",
       "      <td>-0.184626</td>\n",
       "      <td>0.043659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94986</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.060150</td>\n",
       "      <td>-0.068398</td>\n",
       "      <td>-0.083251</td>\n",
       "      <td>-0.058607</td>\n",
       "      <td>0.782389</td>\n",
       "      <td>0.950324</td>\n",
       "      <td>0.622569</td>\n",
       "      <td>1.006318</td>\n",
       "      <td>-0.045289</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.817978</td>\n",
       "      <td>-0.418054</td>\n",
       "      <td>-0.343639</td>\n",
       "      <td>-0.360591</td>\n",
       "      <td>-0.372769</td>\n",
       "      <td>-0.365326</td>\n",
       "      <td>-0.322034</td>\n",
       "      <td>-0.333167</td>\n",
       "      <td>-0.481671</td>\n",
       "      <td>-0.426560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94987</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.060754</td>\n",
       "      <td>-0.039866</td>\n",
       "      <td>-0.083801</td>\n",
       "      <td>-0.028766</td>\n",
       "      <td>0.036553</td>\n",
       "      <td>0.046207</td>\n",
       "      <td>-0.016348</td>\n",
       "      <td>0.048549</td>\n",
       "      <td>-0.048627</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.618471</td>\n",
       "      <td>-0.418054</td>\n",
       "      <td>-0.325791</td>\n",
       "      <td>-0.351315</td>\n",
       "      <td>-0.367643</td>\n",
       "      <td>-0.362559</td>\n",
       "      <td>-0.236040</td>\n",
       "      <td>-0.273182</td>\n",
       "      <td>-0.432163</td>\n",
       "      <td>-0.392973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94988</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.060150</td>\n",
       "      <td>-0.068398</td>\n",
       "      <td>-0.083251</td>\n",
       "      <td>-0.058607</td>\n",
       "      <td>-0.066316</td>\n",
       "      <td>-0.104716</td>\n",
       "      <td>-0.104471</td>\n",
       "      <td>-0.088039</td>\n",
       "      <td>-0.050259</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.817978</td>\n",
       "      <td>-0.912462</td>\n",
       "      <td>-0.361488</td>\n",
       "      <td>-0.388420</td>\n",
       "      <td>-0.393272</td>\n",
       "      <td>-0.393002</td>\n",
       "      <td>-0.322034</td>\n",
       "      <td>-0.393151</td>\n",
       "      <td>-0.531178</td>\n",
       "      <td>-0.628082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94989</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.060150</td>\n",
       "      <td>-0.068398</td>\n",
       "      <td>-0.083251</td>\n",
       "      <td>-0.058607</td>\n",
       "      <td>1.183662</td>\n",
       "      <td>1.376260</td>\n",
       "      <td>0.966317</td>\n",
       "      <td>1.448127</td>\n",
       "      <td>0.113566</td>\n",
       "      <td>...</td>\n",
       "      <td>0.977584</td>\n",
       "      <td>0.570763</td>\n",
       "      <td>-0.343639</td>\n",
       "      <td>-0.379143</td>\n",
       "      <td>-0.383020</td>\n",
       "      <td>-0.387467</td>\n",
       "      <td>-0.322034</td>\n",
       "      <td>-0.333167</td>\n",
       "      <td>-0.036103</td>\n",
       "      <td>-0.124276</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94990</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.060150</td>\n",
       "      <td>-0.068398</td>\n",
       "      <td>-0.083251</td>\n",
       "      <td>-0.058607</td>\n",
       "      <td>-0.066316</td>\n",
       "      <td>-0.104716</td>\n",
       "      <td>-0.104471</td>\n",
       "      <td>-0.088039</td>\n",
       "      <td>-0.050259</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.817978</td>\n",
       "      <td>-0.912462</td>\n",
       "      <td>-0.361488</td>\n",
       "      <td>-0.388420</td>\n",
       "      <td>-0.393272</td>\n",
       "      <td>-0.393002</td>\n",
       "      <td>-0.322034</td>\n",
       "      <td>-0.393151</td>\n",
       "      <td>-0.531178</td>\n",
       "      <td>-0.628082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94991</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.018080</td>\n",
       "      <td>0.002143</td>\n",
       "      <td>-0.012164</td>\n",
       "      <td>-0.001854</td>\n",
       "      <td>0.635767</td>\n",
       "      <td>0.794690</td>\n",
       "      <td>0.496966</td>\n",
       "      <td>0.844884</td>\n",
       "      <td>0.058483</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.219457</td>\n",
       "      <td>-0.170850</td>\n",
       "      <td>-0.343639</td>\n",
       "      <td>-0.369867</td>\n",
       "      <td>-0.342014</td>\n",
       "      <td>-0.293370</td>\n",
       "      <td>-0.150046</td>\n",
       "      <td>-0.213197</td>\n",
       "      <td>-0.283641</td>\n",
       "      <td>-0.292212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94992</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.075378</td>\n",
       "      <td>-0.063254</td>\n",
       "      <td>0.015228</td>\n",
       "      <td>-0.055743</td>\n",
       "      <td>0.752274</td>\n",
       "      <td>0.841593</td>\n",
       "      <td>0.596771</td>\n",
       "      <td>0.442561</td>\n",
       "      <td>-0.065561</td>\n",
       "      <td>...</td>\n",
       "      <td>0.578570</td>\n",
       "      <td>1.188773</td>\n",
       "      <td>-0.325791</td>\n",
       "      <td>-0.369867</td>\n",
       "      <td>-0.367643</td>\n",
       "      <td>-0.359791</td>\n",
       "      <td>0.107936</td>\n",
       "      <td>-0.093228</td>\n",
       "      <td>-0.085611</td>\n",
       "      <td>3.335193</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94993</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.060150</td>\n",
       "      <td>-0.068398</td>\n",
       "      <td>-0.083251</td>\n",
       "      <td>-0.058607</td>\n",
       "      <td>0.061084</td>\n",
       "      <td>0.042086</td>\n",
       "      <td>0.066277</td>\n",
       "      <td>0.012023</td>\n",
       "      <td>-0.050259</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.618471</td>\n",
       "      <td>-0.665258</td>\n",
       "      <td>-0.307942</td>\n",
       "      <td>-0.342038</td>\n",
       "      <td>-0.331762</td>\n",
       "      <td>-0.268462</td>\n",
       "      <td>-0.322034</td>\n",
       "      <td>-0.393151</td>\n",
       "      <td>-0.432163</td>\n",
       "      <td>-0.493734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94994</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.060150</td>\n",
       "      <td>-0.068398</td>\n",
       "      <td>-0.083251</td>\n",
       "      <td>-0.058607</td>\n",
       "      <td>-0.066316</td>\n",
       "      <td>-0.104716</td>\n",
       "      <td>-0.104471</td>\n",
       "      <td>-0.088039</td>\n",
       "      <td>-0.050259</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.817978</td>\n",
       "      <td>-0.912462</td>\n",
       "      <td>-0.361488</td>\n",
       "      <td>-0.388420</td>\n",
       "      <td>-0.393272</td>\n",
       "      <td>-0.393002</td>\n",
       "      <td>-0.322034</td>\n",
       "      <td>-0.393151</td>\n",
       "      <td>-0.531178</td>\n",
       "      <td>-0.628082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94995</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.058556</td>\n",
       "      <td>-0.052479</td>\n",
       "      <td>-0.073425</td>\n",
       "      <td>-0.047882</td>\n",
       "      <td>-0.066316</td>\n",
       "      <td>-0.104716</td>\n",
       "      <td>-0.104471</td>\n",
       "      <td>-0.088039</td>\n",
       "      <td>-0.048657</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.418964</td>\n",
       "      <td>-0.665258</td>\n",
       "      <td>-0.361488</td>\n",
       "      <td>-0.388420</td>\n",
       "      <td>-0.393272</td>\n",
       "      <td>-0.393002</td>\n",
       "      <td>-0.064052</td>\n",
       "      <td>-0.213197</td>\n",
       "      <td>-0.382656</td>\n",
       "      <td>-0.527321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94996</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.066169</td>\n",
       "      <td>-0.056312</td>\n",
       "      <td>-0.086395</td>\n",
       "      <td>-0.052583</td>\n",
       "      <td>-0.101282</td>\n",
       "      <td>0.012339</td>\n",
       "      <td>-0.134424</td>\n",
       "      <td>0.033378</td>\n",
       "      <td>-0.056308</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.219457</td>\n",
       "      <td>-0.541656</td>\n",
       "      <td>-0.343639</td>\n",
       "      <td>-0.379143</td>\n",
       "      <td>-0.388146</td>\n",
       "      <td>-0.390234</td>\n",
       "      <td>0.021942</td>\n",
       "      <td>-0.153213</td>\n",
       "      <td>-0.333148</td>\n",
       "      <td>-0.493734</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94997</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.077121</td>\n",
       "      <td>-0.061655</td>\n",
       "      <td>-0.098673</td>\n",
       "      <td>-0.052371</td>\n",
       "      <td>-0.178244</td>\n",
       "      <td>-0.069354</td>\n",
       "      <td>-0.200353</td>\n",
       "      <td>-0.051360</td>\n",
       "      <td>-0.067312</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.219457</td>\n",
       "      <td>-0.418054</td>\n",
       "      <td>-0.343639</td>\n",
       "      <td>-0.369867</td>\n",
       "      <td>-0.367643</td>\n",
       "      <td>-0.365326</td>\n",
       "      <td>-0.150046</td>\n",
       "      <td>-0.273182</td>\n",
       "      <td>-0.333148</td>\n",
       "      <td>-0.426560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94998</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.092427</td>\n",
       "      <td>0.048580</td>\n",
       "      <td>0.055395</td>\n",
       "      <td>0.037597</td>\n",
       "      <td>-0.146723</td>\n",
       "      <td>-0.078596</td>\n",
       "      <td>-0.118230</td>\n",
       "      <td>-0.077841</td>\n",
       "      <td>0.035012</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.418964</td>\n",
       "      <td>-0.665258</td>\n",
       "      <td>-0.236549</td>\n",
       "      <td>-0.267828</td>\n",
       "      <td>-0.249750</td>\n",
       "      <td>-0.232484</td>\n",
       "      <td>-0.150046</td>\n",
       "      <td>-0.213197</td>\n",
       "      <td>-0.382656</td>\n",
       "      <td>-0.527321</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94999</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.060150</td>\n",
       "      <td>-0.068398</td>\n",
       "      <td>-0.083251</td>\n",
       "      <td>-0.058607</td>\n",
       "      <td>-0.195510</td>\n",
       "      <td>-0.087681</td>\n",
       "      <td>-0.215143</td>\n",
       "      <td>-0.070369</td>\n",
       "      <td>-0.050259</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.817978</td>\n",
       "      <td>-0.912462</td>\n",
       "      <td>-0.343639</td>\n",
       "      <td>-0.379143</td>\n",
       "      <td>-0.388146</td>\n",
       "      <td>-0.381932</td>\n",
       "      <td>-0.322034</td>\n",
       "      <td>-0.393151</td>\n",
       "      <td>-0.531178</td>\n",
       "      <td>-0.594495</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95000</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.060150</td>\n",
       "      <td>-0.068398</td>\n",
       "      <td>-0.083251</td>\n",
       "      <td>-0.058607</td>\n",
       "      <td>-0.171342</td>\n",
       "      <td>-0.094012</td>\n",
       "      <td>-0.151117</td>\n",
       "      <td>-0.082504</td>\n",
       "      <td>-0.050259</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019950</td>\n",
       "      <td>-0.170850</td>\n",
       "      <td>-0.218700</td>\n",
       "      <td>-0.277105</td>\n",
       "      <td>-0.188240</td>\n",
       "      <td>-0.185436</td>\n",
       "      <td>-0.322034</td>\n",
       "      <td>-0.393151</td>\n",
       "      <td>-0.283641</td>\n",
       "      <td>-0.392973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95001</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.060150</td>\n",
       "      <td>-0.068398</td>\n",
       "      <td>-0.083251</td>\n",
       "      <td>-0.058607</td>\n",
       "      <td>-0.066316</td>\n",
       "      <td>-0.104716</td>\n",
       "      <td>-0.104471</td>\n",
       "      <td>-0.088039</td>\n",
       "      <td>-0.050259</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.817978</td>\n",
       "      <td>-0.912462</td>\n",
       "      <td>-0.361488</td>\n",
       "      <td>-0.388420</td>\n",
       "      <td>-0.393272</td>\n",
       "      <td>-0.393002</td>\n",
       "      <td>-0.322034</td>\n",
       "      <td>-0.393151</td>\n",
       "      <td>-0.531178</td>\n",
       "      <td>-0.628082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95002</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.047796</td>\n",
       "      <td>-0.040269</td>\n",
       "      <td>-0.072026</td>\n",
       "      <td>-0.036810</td>\n",
       "      <td>-0.035885</td>\n",
       "      <td>-0.005343</td>\n",
       "      <td>-0.075387</td>\n",
       "      <td>-0.039684</td>\n",
       "      <td>-0.029669</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.418964</td>\n",
       "      <td>-0.047248</td>\n",
       "      <td>-0.290094</td>\n",
       "      <td>-0.342038</td>\n",
       "      <td>-0.306133</td>\n",
       "      <td>-0.238019</td>\n",
       "      <td>-0.150046</td>\n",
       "      <td>-0.213197</td>\n",
       "      <td>-0.382656</td>\n",
       "      <td>-0.292212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95003</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.079589</td>\n",
       "      <td>-0.061129</td>\n",
       "      <td>-0.102607</td>\n",
       "      <td>-0.055323</td>\n",
       "      <td>-0.167990</td>\n",
       "      <td>-0.079038</td>\n",
       "      <td>-0.189477</td>\n",
       "      <td>-0.078445</td>\n",
       "      <td>-0.068277</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.219457</td>\n",
       "      <td>-0.047248</td>\n",
       "      <td>-0.272246</td>\n",
       "      <td>-0.332762</td>\n",
       "      <td>-0.301008</td>\n",
       "      <td>-0.235252</td>\n",
       "      <td>-0.064052</td>\n",
       "      <td>-0.153213</td>\n",
       "      <td>-0.333148</td>\n",
       "      <td>-0.258624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95004</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.068466</td>\n",
       "      <td>-0.055123</td>\n",
       "      <td>-0.091270</td>\n",
       "      <td>-0.053193</td>\n",
       "      <td>-0.064930</td>\n",
       "      <td>-0.068824</td>\n",
       "      <td>0.188301</td>\n",
       "      <td>-0.070101</td>\n",
       "      <td>-0.056491</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.219457</td>\n",
       "      <td>-0.047248</td>\n",
       "      <td>-0.200852</td>\n",
       "      <td>-0.267828</td>\n",
       "      <td>-0.183115</td>\n",
       "      <td>-0.182668</td>\n",
       "      <td>0.021942</td>\n",
       "      <td>-0.093228</td>\n",
       "      <td>-0.283641</td>\n",
       "      <td>-0.225037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95005</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.082597</td>\n",
       "      <td>-0.066065</td>\n",
       "      <td>-0.086295</td>\n",
       "      <td>-0.056387</td>\n",
       "      <td>-0.066316</td>\n",
       "      <td>-0.104716</td>\n",
       "      <td>-0.104471</td>\n",
       "      <td>-0.088039</td>\n",
       "      <td>-0.070997</td>\n",
       "      <td>...</td>\n",
       "      <td>0.379063</td>\n",
       "      <td>1.188773</td>\n",
       "      <td>-0.361488</td>\n",
       "      <td>-0.388420</td>\n",
       "      <td>-0.393272</td>\n",
       "      <td>-0.393002</td>\n",
       "      <td>-0.064052</td>\n",
       "      <td>-0.153213</td>\n",
       "      <td>-0.184626</td>\n",
       "      <td>0.010072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95006</th>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.078077</td>\n",
       "      <td>-0.058220</td>\n",
       "      <td>-0.099852</td>\n",
       "      <td>-0.054788</td>\n",
       "      <td>-0.170866</td>\n",
       "      <td>-0.074120</td>\n",
       "      <td>-0.203668</td>\n",
       "      <td>-0.073105</td>\n",
       "      <td>-0.068274</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.019950</td>\n",
       "      <td>0.199956</td>\n",
       "      <td>-0.307942</td>\n",
       "      <td>-0.342038</td>\n",
       "      <td>-0.362517</td>\n",
       "      <td>-0.359791</td>\n",
       "      <td>-0.064052</td>\n",
       "      <td>-0.213197</td>\n",
       "      <td>-0.283641</td>\n",
       "      <td>-0.258624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95007</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.065898</td>\n",
       "      <td>-0.027189</td>\n",
       "      <td>0.398019</td>\n",
       "      <td>-0.031231</td>\n",
       "      <td>1.524075</td>\n",
       "      <td>0.320533</td>\n",
       "      <td>2.629457</td>\n",
       "      <td>0.103058</td>\n",
       "      <td>0.076402</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.219457</td>\n",
       "      <td>0.447160</td>\n",
       "      <td>-0.183004</td>\n",
       "      <td>-0.258552</td>\n",
       "      <td>-0.177989</td>\n",
       "      <td>-0.179901</td>\n",
       "      <td>0.193930</td>\n",
       "      <td>-0.033244</td>\n",
       "      <td>-0.135118</td>\n",
       "      <td>0.312356</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88621 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       fraud  card_amount_to_avg_3  card_amount_to_max_3  \\\n",
       "6387     0.0             -0.069713             -0.048956   \n",
       "6388     0.0             -0.087416             -0.066921   \n",
       "6389     0.0              0.018664             -0.008213   \n",
       "6390     0.0             -0.067616             -0.055079   \n",
       "6391     0.0             -0.083351             -0.062795   \n",
       "6392     0.0             -0.071883             -0.056158   \n",
       "6393     0.0             -0.069205             -0.056158   \n",
       "6394     0.0             -0.060150             -0.068398   \n",
       "6395     0.0             -0.078011             -0.057377   \n",
       "6396     0.0             -0.060150             -0.068398   \n",
       "6397     0.0             -0.060150             -0.068398   \n",
       "6398     0.0             -0.049298             -0.039252   \n",
       "6399     0.0             -0.055951             -0.042320   \n",
       "6400     0.0             -0.059255             -0.044366   \n",
       "6401     0.0             -0.061895             -0.046411   \n",
       "6402     0.0             -0.079263             -0.060626   \n",
       "6403     0.0             -0.078496             -0.060626   \n",
       "6404     0.0             -0.077788             -0.060626   \n",
       "6405     0.0             -0.077689             -0.060994   \n",
       "6406     0.0             -0.077089             -0.060994   \n",
       "6407     0.0             -0.076529             -0.060994   \n",
       "6408     0.0             -0.056535             -0.035584   \n",
       "6409     0.0             -0.060150             -0.068398   \n",
       "6410     0.0             -0.075764             -0.063865   \n",
       "6411     0.0             -0.086931             -0.066428   \n",
       "6412     0.0             -0.060150             -0.068398   \n",
       "6413     0.0             -0.086014             -0.065497   \n",
       "6414     0.0             -0.060150             -0.068398   \n",
       "6415     0.0              0.072763              0.027008   \n",
       "6416     0.0             -0.088577             -0.068283   \n",
       "...      ...                   ...                   ...   \n",
       "94978    0.0              0.098444              0.040782   \n",
       "94979    0.0             -0.062552             -0.056765   \n",
       "94980    0.0             -0.073711             -0.061837   \n",
       "94981    0.0             -0.063610             -0.054890   \n",
       "94982    0.0             -0.084357             -0.066056   \n",
       "94983    0.0             -0.057380             -0.058455   \n",
       "94984    0.0             -0.087405             -0.067784   \n",
       "94985    0.0             -0.078969             -0.065238   \n",
       "94986    0.0             -0.060150             -0.068398   \n",
       "94987    0.0             -0.060754             -0.039866   \n",
       "94988    0.0             -0.060150             -0.068398   \n",
       "94989    0.0             -0.060150             -0.068398   \n",
       "94990    0.0             -0.060150             -0.068398   \n",
       "94991    0.0              0.018080              0.002143   \n",
       "94992    0.0             -0.075378             -0.063254   \n",
       "94993    0.0             -0.060150             -0.068398   \n",
       "94994    0.0             -0.060150             -0.068398   \n",
       "94995    0.0             -0.058556             -0.052479   \n",
       "94996    0.0             -0.066169             -0.056312   \n",
       "94997    0.0             -0.077121             -0.061655   \n",
       "94998    0.0              0.092427              0.048580   \n",
       "94999    0.0             -0.060150             -0.068398   \n",
       "95000    0.0             -0.060150             -0.068398   \n",
       "95001    0.0             -0.060150             -0.068398   \n",
       "95002    0.0             -0.047796             -0.040269   \n",
       "95003    0.0             -0.079589             -0.061129   \n",
       "95004    0.0             -0.068466             -0.055123   \n",
       "95005    0.0             -0.082597             -0.066065   \n",
       "95006    0.0             -0.078077             -0.058220   \n",
       "95007    0.0              0.065898             -0.027189   \n",
       "\n",
       "       card_amount_to_median_3  card_amount_to_total_3  \\\n",
       "6387                 -0.091941               -0.038273   \n",
       "6388                 -0.108029               -0.057062   \n",
       "6389                 -0.011633               -0.001544   \n",
       "6390                 -0.090036               -0.047327   \n",
       "6391                 -0.104334               -0.052747   \n",
       "6392                 -0.093913               -0.049592   \n",
       "6393                 -0.083251               -0.051649   \n",
       "6394                 -0.083251               -0.058607   \n",
       "6395                 -0.099482               -0.047081   \n",
       "6396                 -0.083251               -0.058607   \n",
       "6397                 -0.083251               -0.058607   \n",
       "6398                 -0.077698               -0.048107   \n",
       "6399                 -0.081030               -0.051619   \n",
       "6400                 -0.084317               -0.053368   \n",
       "6401                 -0.085473               -0.054517   \n",
       "6402                 -0.100911               -0.057332   \n",
       "6403                 -0.100911               -0.057383   \n",
       "6404                 -0.100911               -0.057430   \n",
       "6405                 -0.101310               -0.057528   \n",
       "6406                 -0.100953               -0.057565   \n",
       "6407                 -0.100562               -0.057599   \n",
       "6408                 -0.079966               -0.024288   \n",
       "6409                 -0.083251               -0.058607   \n",
       "6410                 -0.094279               -0.055825   \n",
       "6411                 -0.107588               -0.056547   \n",
       "6412                 -0.083251               -0.058607   \n",
       "6413                 -0.106754               -0.055573   \n",
       "6414                 -0.083251               -0.058607   \n",
       "6415                  0.009272               -0.001427   \n",
       "6416                 -0.108960               -0.058528   \n",
       "...                        ...                     ...   \n",
       "94978                 0.060863                0.040790   \n",
       "94979                -0.070329               -0.049296   \n",
       "94980                -0.091710               -0.054584   \n",
       "94981                -0.086057               -0.049670   \n",
       "94982                -0.105084               -0.057409   \n",
       "94983                -0.021172               -0.050251   \n",
       "94984                -0.106695               -0.058088   \n",
       "94985                -0.085440               -0.055979   \n",
       "94986                -0.083251               -0.058607   \n",
       "94987                -0.083801               -0.028766   \n",
       "94988                -0.083251               -0.058607   \n",
       "94989                -0.083251               -0.058607   \n",
       "94990                -0.083251               -0.058607   \n",
       "94991                -0.012164               -0.001854   \n",
       "94992                 0.015228               -0.055743   \n",
       "94993                -0.083251               -0.058607   \n",
       "94994                -0.083251               -0.058607   \n",
       "94995                -0.073425               -0.047882   \n",
       "94996                -0.086395               -0.052583   \n",
       "94997                -0.098673               -0.052371   \n",
       "94998                 0.055395                0.037597   \n",
       "94999                -0.083251               -0.058607   \n",
       "95000                -0.083251               -0.058607   \n",
       "95001                -0.083251               -0.058607   \n",
       "95002                -0.072026               -0.036810   \n",
       "95003                -0.102607               -0.055323   \n",
       "95004                -0.091270               -0.053193   \n",
       "95005                -0.086295               -0.056387   \n",
       "95006                -0.099852               -0.054788   \n",
       "95007                 0.398019               -0.031231   \n",
       "\n",
       "       merchant_amount_to_avg_3  merchant_amount_to_max_3  \\\n",
       "6387                  -0.201987                 -0.094556   \n",
       "6388                  -0.133731                 -0.022105   \n",
       "6389                  -0.066316                 -0.104716   \n",
       "6390                  -0.066316                 -0.104716   \n",
       "6391                  -0.178009                 -0.094020   \n",
       "6392                  -0.117387                 -0.094627   \n",
       "6393                  -0.117000                 -0.094627   \n",
       "6394                  -0.113472                 -0.094293   \n",
       "6395                  -0.066316                 -0.104716   \n",
       "6396                   0.189849                  0.321364   \n",
       "6397                  -0.188953                 -0.080721   \n",
       "6398                   0.163550                 -0.065003   \n",
       "6399                   0.118201                 -0.069183   \n",
       "6400                   0.088107                 -0.071970   \n",
       "6401                   0.059438                 -0.074757   \n",
       "6402                  -0.116658                 -0.094126   \n",
       "6403                  -0.116303                 -0.094126   \n",
       "6404                  -0.115953                 -0.094126   \n",
       "6405                  -0.120152                 -0.094627   \n",
       "6406                  -0.119798                 -0.094627   \n",
       "6407                  -0.119448                 -0.094627   \n",
       "6408                  -0.158190                 -0.078758   \n",
       "6409                  -0.093920                 -0.069015   \n",
       "6410                  -0.066316                 -0.104716   \n",
       "6411                  -0.136226                 -0.075530   \n",
       "6412                   0.730359                 -0.001936   \n",
       "6413                  -0.122747                 -0.094488   \n",
       "6414                   0.045237                  0.167863   \n",
       "6415                   0.448557                  0.595973   \n",
       "6416                  -0.120700                 -0.094293   \n",
       "...                         ...                       ...   \n",
       "94978                  0.171832                  0.025746   \n",
       "94979                 -0.096327                 -0.052646   \n",
       "94980                 -0.144250                 -0.075348   \n",
       "94981                  0.173478                  0.188512   \n",
       "94982                 -0.066316                 -0.104716   \n",
       "94983                 -0.066316                 -0.104716   \n",
       "94984                 -0.193085                 -0.099197   \n",
       "94985                 -0.066316                 -0.104716   \n",
       "94986                  0.782389                  0.950324   \n",
       "94987                  0.036553                  0.046207   \n",
       "94988                 -0.066316                 -0.104716   \n",
       "94989                  1.183662                  1.376260   \n",
       "94990                 -0.066316                 -0.104716   \n",
       "94991                  0.635767                  0.794690   \n",
       "94992                  0.752274                  0.841593   \n",
       "94993                  0.061084                  0.042086   \n",
       "94994                 -0.066316                 -0.104716   \n",
       "94995                 -0.066316                 -0.104716   \n",
       "94996                 -0.101282                  0.012339   \n",
       "94997                 -0.178244                 -0.069354   \n",
       "94998                 -0.146723                 -0.078596   \n",
       "94999                 -0.195510                 -0.087681   \n",
       "95000                 -0.171342                 -0.094012   \n",
       "95001                 -0.066316                 -0.104716   \n",
       "95002                 -0.035885                 -0.005343   \n",
       "95003                 -0.167990                 -0.079038   \n",
       "95004                 -0.064930                 -0.068824   \n",
       "95005                 -0.066316                 -0.104716   \n",
       "95006                 -0.170866                 -0.074120   \n",
       "95007                  1.524075                  0.320533   \n",
       "\n",
       "       merchant_amount_to_median_3  merchant_amount_to_total_3  \\\n",
       "6387                     -0.220692                   -0.077500   \n",
       "6388                     -0.162222                   -0.002350   \n",
       "6389                     -0.104471                   -0.088039   \n",
       "6390                     -0.104471                   -0.088039   \n",
       "6391                     -0.188474                   -0.085576   \n",
       "6392                     -0.106166                   -0.086819   \n",
       "6393                     -0.105324                   -0.086828   \n",
       "6394                     -0.100346                   -0.086798   \n",
       "6395                     -0.104471                   -0.088039   \n",
       "6396                      0.114972                    0.353919   \n",
       "6397                     -0.209527                   -0.063150   \n",
       "6398                      0.257528                   -0.083346   \n",
       "6399                      0.203361                   -0.083959   \n",
       "6400                      0.169459                   -0.084373   \n",
       "6401                      0.135557                   -0.084760   \n",
       "6402                     -0.100063                   -0.086903   \n",
       "6403                     -0.100063                   -0.086911   \n",
       "6404                     -0.101280                   -0.086919   \n",
       "6405                     -0.108463                   -0.086979   \n",
       "6406                     -0.107325                   -0.086986   \n",
       "6407                     -0.106166                   -0.086993   \n",
       "6408                     -0.169368                   -0.078246   \n",
       "6409                     -0.093982                   -0.079944   \n",
       "6410                     -0.104471                   -0.088039   \n",
       "6411                     -0.123136                   -0.067303   \n",
       "6412                      1.021421                   -0.077457   \n",
       "6413                     -0.104471                   -0.087051   \n",
       "6414                     -0.008909                    0.194698   \n",
       "6415                      0.336594                    0.638762   \n",
       "6416                     -0.102097                   -0.087038   \n",
       "...                            ...                         ...   \n",
       "94978                     0.533422                    0.017491   \n",
       "94979                     0.003178                   -0.062665   \n",
       "94980                    -0.137527                   -0.075687   \n",
       "94981                     0.010783                    0.053272   \n",
       "94982                    -0.104471                   -0.088039   \n",
       "94983                    -0.104471                   -0.088039   \n",
       "94984                    -0.202799                   -0.085133   \n",
       "94985                    -0.104471                   -0.088039   \n",
       "94986                     0.622569                    1.006318   \n",
       "94987                    -0.016348                    0.048549   \n",
       "94988                    -0.104471                   -0.088039   \n",
       "94989                     0.966317                    1.448127   \n",
       "94990                    -0.104471                   -0.088039   \n",
       "94991                     0.496966                    0.844884   \n",
       "94992                     0.596771                    0.442561   \n",
       "94993                     0.066277                    0.012023   \n",
       "94994                    -0.104471                   -0.088039   \n",
       "94995                    -0.104471                   -0.088039   \n",
       "94996                    -0.134424                    0.033378   \n",
       "94997                    -0.200353                   -0.051360   \n",
       "94998                    -0.118230                   -0.077841   \n",
       "94999                    -0.215143                   -0.070369   \n",
       "95000                    -0.151117                   -0.082504   \n",
       "95001                    -0.104471                   -0.088039   \n",
       "95002                    -0.075387                   -0.039684   \n",
       "95003                    -0.189477                   -0.078445   \n",
       "95004                     0.188301                   -0.070101   \n",
       "95005                    -0.104471                   -0.088039   \n",
       "95006                    -0.203668                   -0.073105   \n",
       "95007                     2.629457                    0.103058   \n",
       "\n",
       "       card_amount_to_avg_7        ...          merchnum_per_card_14  \\\n",
       "6387              -0.059868        ...                     -0.618471   \n",
       "6388              -0.078011        ...                     -0.418964   \n",
       "6389               0.117367        ...                      0.578570   \n",
       "6390              -0.047285        ...                     -0.418964   \n",
       "6391              -0.073573        ...                     -0.219457   \n",
       "6392              -0.056506        ...                     -0.817978   \n",
       "6393              -0.055660        ...                     -0.817978   \n",
       "6394              -0.069245        ...                     -0.618471   \n",
       "6395              -0.068208        ...                     -0.817978   \n",
       "6396              -0.050259        ...                     -0.618471   \n",
       "6397               0.427385        ...                     -0.418964   \n",
       "6398              -0.045780        ...                     -0.817978   \n",
       "6399              -0.049545        ...                     -0.817978   \n",
       "6400              -0.051900        ...                     -0.817978   \n",
       "6401              -0.054146        ...                     -0.817978   \n",
       "6402              -0.070236        ...                     -0.817978   \n",
       "6403              -0.069947        ...                     -0.817978   \n",
       "6404              -0.069667        ...                     -0.817978   \n",
       "6405              -0.069855        ...                     -0.817978   \n",
       "6406              -0.069596        ...                     -0.817978   \n",
       "6407              -0.069344        ...                     -0.817978   \n",
       "6408              -0.056671        ...                     -0.418964   \n",
       "6409              -0.050259        ...                     -0.618471   \n",
       "6410              -0.059364        ...                      0.578570   \n",
       "6411              -0.077171        ...                     -0.019950   \n",
       "6412              -0.068270        ...                     -0.019950   \n",
       "6413              -0.077976        ...                     -0.019950   \n",
       "6414              -0.050259        ...                     -0.817978   \n",
       "6415              -0.031712        ...                      1.775611   \n",
       "6416              -0.078944        ...                      1.775611   \n",
       "...                     ...        ...                           ...   \n",
       "94978              0.109107        ...                     -0.418964   \n",
       "94979             -0.052673        ...                     -0.219457   \n",
       "94980             -0.063886        ...                     -0.219457   \n",
       "94981             -0.053736        ...                      0.379063   \n",
       "94982             -0.074584        ...                      0.379063   \n",
       "94983             -0.055430        ...                     -0.418964   \n",
       "94984             -0.077219        ...                      0.179556   \n",
       "94985             -0.067075        ...                      0.179556   \n",
       "94986             -0.045289        ...                     -0.817978   \n",
       "94987             -0.048627        ...                     -0.618471   \n",
       "94988             -0.050259        ...                     -0.817978   \n",
       "94989              0.113566        ...                      0.977584   \n",
       "94990             -0.050259        ...                     -0.817978   \n",
       "94991              0.058483        ...                     -0.219457   \n",
       "94992             -0.065561        ...                      0.578570   \n",
       "94993             -0.050259        ...                     -0.618471   \n",
       "94994             -0.050259        ...                     -0.817978   \n",
       "94995             -0.048657        ...                     -0.418964   \n",
       "94996             -0.056308        ...                     -0.219457   \n",
       "94997             -0.067312        ...                     -0.219457   \n",
       "94998              0.035012        ...                     -0.418964   \n",
       "94999             -0.050259        ...                     -0.817978   \n",
       "95000             -0.050259        ...                     -0.019950   \n",
       "95001             -0.050259        ...                     -0.817978   \n",
       "95002             -0.029669        ...                     -0.418964   \n",
       "95003             -0.068277        ...                     -0.219457   \n",
       "95004             -0.056491        ...                     -0.219457   \n",
       "95005             -0.070997        ...                      0.379063   \n",
       "95006             -0.068274        ...                     -0.019950   \n",
       "95007              0.076402        ...                     -0.219457   \n",
       "\n",
       "       merchnum_per_card_28  merchant_frequency_3  merchant_frequency_7  \\\n",
       "6387              -0.788860             -0.343639             -0.379143   \n",
       "6388              -0.294452             -0.343639             -0.379143   \n",
       "6389               0.199956             -0.361488             -0.388420   \n",
       "6390              -0.418054             -0.361488             -0.388420   \n",
       "6391              -0.047248             -0.093762             -0.193618   \n",
       "6392              -0.788860              1.155626              2.004854   \n",
       "6393              -0.788860              1.173474              2.014130   \n",
       "6394              -0.418054              1.191323              2.023406   \n",
       "6395              -0.541656             -0.361488             -0.379143   \n",
       "6396              -0.170850             -0.343639             -0.379143   \n",
       "6397              -0.418054             -0.343639             -0.369867   \n",
       "6398              -0.912462              1.209171              2.032682   \n",
       "6399              -0.912462              1.227020              2.041959   \n",
       "6400              -0.912462              1.244868              2.051235   \n",
       "6401              -0.912462              1.262716              2.060511   \n",
       "6402              -0.912462              1.280565              2.069787   \n",
       "6403              -0.912462              1.298413              2.079064   \n",
       "6404              -0.912462              1.316262              2.088340   \n",
       "6405              -0.912462              1.334110              2.097616   \n",
       "6406              -0.912462              1.351958              2.106892   \n",
       "6407              -0.912462              1.369807              2.116169   \n",
       "6408              -0.047248             -0.254397             -0.323486   \n",
       "6409               0.076354             -0.075913             -0.184342   \n",
       "6410               0.447160             -0.361488             -0.388420   \n",
       "6411               0.076354             -0.290094             -0.295657   \n",
       "6412               0.323558              1.387655              2.125445   \n",
       "6413               0.323558              1.405504              2.134721   \n",
       "6414              -0.788860             -0.343639             -0.379143   \n",
       "6415               1.312375             -0.343639             -0.379143   \n",
       "6416               1.312375              1.423352              2.143997   \n",
       "...                     ...                   ...                   ...   \n",
       "94978             -0.665258             -0.290094             -0.295657   \n",
       "94979             -0.541656             -0.272246             -0.286381   \n",
       "94980             -0.541656             -0.254397             -0.277105   \n",
       "94981             -0.047248             -0.307942             -0.351315   \n",
       "94982             -0.047248             -0.361488             -0.388420   \n",
       "94983             -0.047248             -0.361488             -0.369867   \n",
       "94984              0.941569             -0.236549             -0.286381   \n",
       "94985              0.941569             -0.361488             -0.388420   \n",
       "94986             -0.418054             -0.343639             -0.360591   \n",
       "94987             -0.418054             -0.325791             -0.351315   \n",
       "94988             -0.912462             -0.361488             -0.388420   \n",
       "94989              0.570763             -0.343639             -0.379143   \n",
       "94990             -0.912462             -0.361488             -0.388420   \n",
       "94991             -0.170850             -0.343639             -0.369867   \n",
       "94992              1.188773             -0.325791             -0.369867   \n",
       "94993             -0.665258             -0.307942             -0.342038   \n",
       "94994             -0.912462             -0.361488             -0.388420   \n",
       "94995             -0.665258             -0.361488             -0.388420   \n",
       "94996             -0.541656             -0.343639             -0.379143   \n",
       "94997             -0.418054             -0.343639             -0.369867   \n",
       "94998             -0.665258             -0.236549             -0.267828   \n",
       "94999             -0.912462             -0.343639             -0.379143   \n",
       "95000             -0.170850             -0.218700             -0.277105   \n",
       "95001             -0.912462             -0.361488             -0.388420   \n",
       "95002             -0.047248             -0.290094             -0.342038   \n",
       "95003             -0.047248             -0.272246             -0.332762   \n",
       "95004             -0.047248             -0.200852             -0.267828   \n",
       "95005              1.188773             -0.361488             -0.388420   \n",
       "95006              0.199956             -0.307942             -0.342038   \n",
       "95007              0.447160             -0.183004             -0.258552   \n",
       "\n",
       "       merchant_frequency_14  merchant_frequency_28  card_frequency_3  \\\n",
       "6387               -0.388146              -0.387467         -0.236040   \n",
       "6388               -0.388146              -0.390234         -0.236040   \n",
       "6389               -0.393272              -0.393002         -0.150046   \n",
       "6390               -0.393272              -0.393002         -0.150046   \n",
       "6391               -0.208743              -0.207576         -0.236040   \n",
       "6392                1.856948               1.660517         -0.150046   \n",
       "6393                1.862074               1.663285         -0.064052   \n",
       "6394                1.867200               1.666052         -0.322034   \n",
       "6395               -0.388146              -0.390234         -0.236040   \n",
       "6396               -0.383020              -0.384699         -0.322034   \n",
       "6397               -0.367643              -0.354256         -0.322034   \n",
       "6398                1.872325               1.668820          0.021942   \n",
       "6399                1.877451               1.671587          0.107936   \n",
       "6400                1.882577               1.674355          0.193930   \n",
       "6401                1.887703               1.677123          0.279924   \n",
       "6402                1.892828               1.679890          0.365918   \n",
       "6403                1.897954               1.682658          0.451912   \n",
       "6404                1.903080               1.685425          0.537906   \n",
       "6405                1.908206               1.688193          0.623900   \n",
       "6406                1.913332               1.690960          0.709894   \n",
       "6407                1.918457               1.693728          0.795888   \n",
       "6408               -0.306133              -0.307208         -0.236040   \n",
       "6409               -0.203618              -0.204809         -0.322034   \n",
       "6410               -0.388146              -0.384699          0.107936   \n",
       "6411               -0.275379              -0.285067         -0.236040   \n",
       "6412                1.923583               1.696495         -0.322034   \n",
       "6413                1.928709               1.699263         -0.236040   \n",
       "6414               -0.377894              -0.370861         -0.322034   \n",
       "6415               -0.383020              -0.387467         -0.064052   \n",
       "6416                1.933835               1.702030          0.021942   \n",
       "...                      ...                    ...               ...   \n",
       "94978              -0.265127              -0.240787         -0.150046   \n",
       "94979              -0.260001              -0.238019         -0.064052   \n",
       "94980              -0.254876              -0.235252          0.021942   \n",
       "94981              -0.311259              -0.240787         -0.064052   \n",
       "94982              -0.372769              -0.376397          0.021942   \n",
       "94983              -0.377894              -0.368094          0.021942   \n",
       "94984              -0.193366              -0.188203         -0.064052   \n",
       "94985              -0.388146              -0.390234          0.021942   \n",
       "94986              -0.372769              -0.365326         -0.322034   \n",
       "94987              -0.367643              -0.362559         -0.236040   \n",
       "94988              -0.393272              -0.393002         -0.322034   \n",
       "94989              -0.383020              -0.387467         -0.322034   \n",
       "94990              -0.393272              -0.393002         -0.322034   \n",
       "94991              -0.342014              -0.293370         -0.150046   \n",
       "94992              -0.367643              -0.359791          0.107936   \n",
       "94993              -0.331762              -0.268462         -0.322034   \n",
       "94994              -0.393272              -0.393002         -0.322034   \n",
       "94995              -0.393272              -0.393002         -0.064052   \n",
       "94996              -0.388146              -0.390234          0.021942   \n",
       "94997              -0.367643              -0.365326         -0.150046   \n",
       "94998              -0.249750              -0.232484         -0.150046   \n",
       "94999              -0.388146              -0.381932         -0.322034   \n",
       "95000              -0.188240              -0.185436         -0.322034   \n",
       "95001              -0.393272              -0.393002         -0.322034   \n",
       "95002              -0.306133              -0.238019         -0.150046   \n",
       "95003              -0.301008              -0.235252         -0.064052   \n",
       "95004              -0.183115              -0.182668          0.021942   \n",
       "95005              -0.393272              -0.393002         -0.064052   \n",
       "95006              -0.362517              -0.359791         -0.064052   \n",
       "95007              -0.177989              -0.179901          0.193930   \n",
       "\n",
       "       card_frequency_7  card_frequency_14  card_frequency_28  \n",
       "6387          -0.333167          -0.432163          -0.560908  \n",
       "6388          -0.213197          -0.333148          -0.392973  \n",
       "6389          -0.033244           0.062912          -0.157863  \n",
       "6390          -0.213197          -0.382656          -0.426560  \n",
       "6391          -0.333167          -0.234133          -0.225037  \n",
       "6392          -0.093228          -0.234133          -0.292212  \n",
       "6393          -0.033244          -0.184626          -0.258624  \n",
       "6394          -0.033244          -0.085611          -0.191450  \n",
       "6395          -0.333167          -0.481671          -0.460147  \n",
       "6396          -0.393151          -0.432163          -0.359386  \n",
       "6397          -0.273182          -0.283641          -0.392973  \n",
       "6398           0.626587           0.508479           0.178008  \n",
       "6399           0.686571           0.557986           0.211595  \n",
       "6400           0.746556           0.607494           0.245182  \n",
       "6401           0.806541           0.657001           0.278769  \n",
       "6402           0.866525           0.706509           0.312356  \n",
       "6403           0.926510           0.756016           0.345943  \n",
       "6404           0.986494           0.805524           0.379530  \n",
       "6405           1.046479           0.855031           0.413117  \n",
       "6406           1.106463           0.904538           0.446704  \n",
       "6407           1.166448           0.954046           0.480291  \n",
       "6408          -0.273182          -0.382656          -0.225037  \n",
       "6409          -0.393151          -0.432163          -0.225037  \n",
       "6410           0.086726           0.013404           0.043659  \n",
       "6411          -0.333167          -0.135118          -0.157863  \n",
       "6412           0.206695           0.260941           0.211595  \n",
       "6413           0.266679           0.310449           0.245182  \n",
       "6414          -0.393151          -0.531178          -0.560908  \n",
       "6415           0.266679           0.409464           0.413117  \n",
       "6416           0.326664           0.458971           0.446704  \n",
       "...                 ...                ...                ...  \n",
       "94978         -0.273182          -0.333148          -0.493734  \n",
       "94979         -0.213197          -0.283641          -0.460147  \n",
       "94980         -0.153213          -0.234133          -0.426560  \n",
       "94981         -0.213197           0.013404          -0.157863  \n",
       "94982         -0.153213           0.062912          -0.124276  \n",
       "94983         -0.093228          -0.283641          -0.225037  \n",
       "94984         -0.153213          -0.234133           0.010072  \n",
       "94985         -0.093228          -0.184626           0.043659  \n",
       "94986         -0.333167          -0.481671          -0.426560  \n",
       "94987         -0.273182          -0.432163          -0.392973  \n",
       "94988         -0.393151          -0.531178          -0.628082  \n",
       "94989         -0.333167          -0.036103          -0.124276  \n",
       "94990         -0.393151          -0.531178          -0.628082  \n",
       "94991         -0.213197          -0.283641          -0.292212  \n",
       "94992         -0.093228          -0.085611           3.335193  \n",
       "94993         -0.393151          -0.432163          -0.493734  \n",
       "94994         -0.393151          -0.531178          -0.628082  \n",
       "94995         -0.213197          -0.382656          -0.527321  \n",
       "94996         -0.153213          -0.333148          -0.493734  \n",
       "94997         -0.273182          -0.333148          -0.426560  \n",
       "94998         -0.213197          -0.382656          -0.527321  \n",
       "94999         -0.393151          -0.531178          -0.594495  \n",
       "95000         -0.393151          -0.283641          -0.392973  \n",
       "95001         -0.393151          -0.531178          -0.628082  \n",
       "95002         -0.213197          -0.382656          -0.292212  \n",
       "95003         -0.153213          -0.333148          -0.258624  \n",
       "95004         -0.093228          -0.283641          -0.225037  \n",
       "95005         -0.153213          -0.184626           0.010072  \n",
       "95006         -0.213197          -0.283641          -0.258624  \n",
       "95007         -0.033244          -0.135118           0.312356  \n",
       "\n",
       "[88621 rows x 57 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.06971252, -0.04895621, -0.09194127, ..., -0.33316654,\n",
       "        -0.43216314, -0.56090816],\n",
       "       [-0.0874164 , -0.06692074, -0.10802883, ..., -0.21319737,\n",
       "        -0.3331482 , -0.39297275],\n",
       "       [ 0.01866392, -0.00821262, -0.0116334 , ..., -0.03324362,\n",
       "         0.06291154, -0.15786318],\n",
       "       ..., \n",
       "       [-0.08259652, -0.06606494, -0.08629461, ..., -0.15321279,\n",
       "        -0.1846258 ,  0.01007222],\n",
       "       [-0.07807729, -0.05822039, -0.09985196, ..., -0.21319737,\n",
       "        -0.28364074, -0.25862443],\n",
       "       [ 0.06589751, -0.02718863,  0.39801873, ..., -0.03324362,\n",
       "        -0.13511833,  0.31235595]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set:\n",
      "Number of Frauds:  197.0\n",
      "Total number of records:  59080\n",
      "Fraud rate:  0.00333446174678\n",
      "\n",
      "Testing set:\n",
      "Number of Frauds:  98.0\n",
      "Total number of records:  29541\n",
      "Fraud rate:  0.00331742324227\n"
     ]
    }
   ],
   "source": [
    "# train-testing split with 2 to 1 proportion\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, test_size=0.33333, random_state=10)\n",
    "print \"Training set:\"\n",
    "print \"Number of Frauds: \",\n",
    "print sum(y_train)\n",
    "print \"Total number of records: \",\n",
    "print len(y_train)\n",
    "print \"Fraud rate: \",\n",
    "print sum(y_train) / len(y_train)\n",
    "print \"\\nTesting set:\"\n",
    "print \"Number of Frauds: \",\n",
    "print sum(y_test)\n",
    "print \"Total number of records: \",\n",
    "print len(y_test)\n",
    "print \"Fraud rate: \",\n",
    "print sum(y_test) / len(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selction Based on Mutual Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.00044281  0.00049552  0.00069896  0.00044826  0.00235717  0.00251673\n",
      "  0.0025326   0.00255604  0.00051322  0.00070844  0.00115503  0.00060054\n",
      "  0.00157901  0.00320562  0.00216894  0.00192025  0.00054466  0.0009193\n",
      "  0.00135411  0.00038589  0.00144542  0.00286214  0.00222356  0.00194538\n",
      "  0.00103461  0.00140082  0.001596    0.00022461  0.00152065  0.00326159\n",
      "  0.00298277  0.00166248  0.00357219  0.00108892  0.00631545  0.00112536\n",
      "  0.00477936  0.00625549  0.00576165  0.00271583  0.00595777  0.0008107\n",
      "  0.00581137  0.00103857  0.00539597  0.00524356  0.00283346  0.00291637\n",
      "  0.0046688   0.00370249  0.00253918  0.00288346  0.00291591  0.00193846\n",
      "  0.0015109   0.00089417]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.text.Text at 0x10e75cf10>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjAAAAGHCAYAAACu1mg/AAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x10e9ee850>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# MI feature selection\n",
    "MI = mutual_info_classif(features,labels)\n",
    "print MI\n",
    "\n",
    "%matplotlib inline\n",
    "plt.bar(range(1,len(MI)+1), MI)\n",
    "plt.title(\"Mutual Information Plot\")\n",
    "plt.xlabel(\"Variable Index\")\n",
    "plt.ylabel(\"Mutual Information\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13\n",
      "9\n",
      "7\n"
     ]
    }
   ],
   "source": [
    "print len(np.array(range(len(MI)))[MI > 0.003])\n",
    "print len(np.array(range(len(MI)))[MI > 0.004])\n",
    "print len(np.array(range(len(MI)))[MI > 0.005])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['zip_with_merchnum_7', 'cardnum_per_merch_3', 'cardnum_per_merch_7',\n",
       "       'merchnum_per_card_3', 'zip_with_merchnum_14',\n",
       "       'zip_with_merchnum_28', 'cardnum_per_merch_14',\n",
       "       'cardnum_per_merch_28', 'merchant_frequency_3'], dtype=object)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns.values[[i+1 for i in np.array(range(len(MI)))[MI > 0.004]]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.00631545,  0.00477936,  0.00625549,  0.00576165,  0.00595777,\n",
       "        0.00581137,  0.00539597,  0.00524356,  0.0046688 ])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MI[np.array(range(len(MI)))[MI > 0.004]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________NB________\n",
      "Accuracy score is 0.964286117286\n",
      "AUC score is 0.596933413468\n",
      "FDR is 0.227118644068\n",
      "_________LR________\n",
      "Accuracy score is 0.996998454091\n",
      "AUC score is 0.559288068814\n",
      "FDR is 0.118644067797\n",
      "_________RF________\n",
      "Accuracy score is 0.998115570802\n",
      "AUC score is 0.72370617017\n",
      "FDR is 0.447457627119\n",
      "_________SVM________\n",
      "Accuracy score is 0.997133862177\n",
      "AUC score is 0.569491525424\n",
      "FDR is 0.138983050847\n",
      "_________NN________\n",
      "Accuracy score is 0.997348258313\n",
      "AUC score is 0.608451932882\n",
      "FDR is 0.216949152542\n"
     ]
    }
   ],
   "source": [
    "# select only variables with MI larger than 0.005\n",
    "selected = np.array(range(len(MI)))[MI > 0.004]\n",
    "features_sub = features[:,selected]\n",
    "\n",
    "clf = GaussianNB()\n",
    "clf.fit(features_sub, labels)\n",
    "score = clf.score(features_sub, labels)\n",
    "print \"_________NB________\"\n",
    "print \"Accuracy score is\", score\n",
    "predictions = clf.predict(features_sub)\n",
    "print \"AUC score is\", roc_auc_score(labels, predictions)\n",
    "matrix = confusion_matrix(labels, predictions)\n",
    "print \"FDR is\", matrix[1,1]/sum(labels)\n",
    "\n",
    "clf = LogisticRegression()\n",
    "clf.fit(features_sub, labels)\n",
    "score = clf.score(features_sub, labels)\n",
    "print \"_________LR________\"\n",
    "print \"Accuracy score is\", score\n",
    "predictions = clf.predict(features_sub)\n",
    "print \"AUC score is\", roc_auc_score(labels, predictions)\n",
    "matrix = confusion_matrix(labels, predictions)\n",
    "print \"FDR is\", matrix[1,1]/sum(labels)\n",
    "\n",
    "clf = RandomForestClassifier(n_estimators = 25, max_depth = 20, min_samples_leaf = 5, random_state = 42, n_jobs = 3)\n",
    "clf.fit(features_sub, labels)\n",
    "score = clf.score(features_sub, labels)\n",
    "print \"_________RF________\"\n",
    "print \"Accuracy score is\", score\n",
    "predictions = clf.predict(features_sub)\n",
    "print \"AUC score is\", roc_auc_score(labels, predictions)\n",
    "matrix = confusion_matrix(labels, predictions)\n",
    "print \"FDR is\", matrix[1,1]/sum(labels)\n",
    "\n",
    "clf = SVC()\n",
    "clf.fit(features_sub, labels)\n",
    "score = clf.score(features_sub, labels)\n",
    "print \"_________SVM________\"\n",
    "print \"Accuracy score is\", score\n",
    "predictions = clf.predict(features_sub)\n",
    "print \"AUC score is\", roc_auc_score(labels, predictions)\n",
    "matrix = confusion_matrix(labels, predictions)\n",
    "print \"FDR is\", matrix[1,1]/sum(labels)\n",
    "\n",
    "clf = MLPClassifier()\n",
    "clf.fit(features_sub, labels)\n",
    "score = clf.score(features_sub, labels)\n",
    "print \"_________NN________\"\n",
    "print \"Accuracy score is\", score\n",
    "predictions = clf.predict(features_sub)\n",
    "print \"AUC score is\", roc_auc_score(labels, predictions)\n",
    "matrix = confusion_matrix(labels, predictions)\n",
    "print \"FDR is\", matrix[1,1]/sum(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forward Feature Selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# forward selection algorithm\n",
    "def forward_selection(feature, label, clf, criteria):\n",
    "    '''\n",
    "    feature: ndarray of all the feature\n",
    "    label: series of fraud label\n",
    "    clf: classifier\n",
    "    criteria: \"accuracy\", \"AUC\" or \"FDR\"\n",
    "    \n",
    "    print the whole feature selection process and feature selected in the end\n",
    "    \n",
    "    return the index list of features selected\n",
    "    '''\n",
    "    \n",
    "    # initialize counter and comparison flag\n",
    "    max_accuracy = 0\n",
    "    added_features = []\n",
    "    count = 0\n",
    "    print \"Starting........ Selection criteria is {crit}, baseline score is {baseline}\".format(\n",
    "        crit = criteria,\n",
    "        baseline = max_accuracy)\n",
    "    # loop until all the new models give a worse result\n",
    "    while True:\n",
    "        count += 1\n",
    "        accuracy = {}\n",
    "        # feature_lst is the list for all the feature indice except those features have been selected in previous round\n",
    "        feature_lst = [i for i in range(feature.shape[1]) if i not in added_features]\n",
    "        # add one feature in feature_list each time\n",
    "        for i in feature_lst:\n",
    "            feature_sub = feature[:,added_features+[i]]\n",
    "            if count == 1:\n",
    "                # change the shape of ndarray to make it acceptable for sklearn\n",
    "                feature_sub = feature_sub.reshape(feature_sub.shape[0],1)\n",
    "            # loop over to create a dict accuracy with feature index as key, and correponding accuracy as value\n",
    "            clf_clone = clone(clf)\n",
    "            clf_clone.fit(feature_sub, label)\n",
    "            if criteria == \"accuracy\":\n",
    "                accuracy[i] = clf_clone.score(feature_sub, label)\n",
    "            elif criteria == \"AUC\":\n",
    "                prediction = clf_clone.predict(feature_sub)\n",
    "                accuracy[i] = roc_auc_score(label, prediction)\n",
    "            elif criteria == \"FDR\":\n",
    "                prediction = clf_clone.predict(feature_sub)\n",
    "                matrix = confusion_matrix(label, prediction)\n",
    "                accuracy[i] = matrix[1,1]/sum(label)\n",
    "        # when the accuracy dict is empty, indicating it's the last round with no left features, end the loop\n",
    "        if accuracy == {}:\n",
    "            print \"Forward selection ended.\"\n",
    "            print \"Selected features are \",\n",
    "            print final_feature_lst\n",
    "            return feature_index\n",
    "            break\n",
    "        # if it's not the last round, calculate the best result in current round\n",
    "        current_max = max(accuracy.values())\n",
    "        # if a not worse best result is generated, update added_features list\n",
    "        if current_max >= max_accuracy:\n",
    "            max_index = accuracy.keys()[accuracy.values().index(current_max)]\n",
    "            added_features.append(max_index)\n",
    "            feature_name = df.columns.values[max_index+1]\n",
    "            # do not updated the final_feature_list until a better result is generated (always make sure fewer features)\n",
    "            if current_max > max_accuracy:\n",
    "                final_feature_lst = list(df.columns.values[[i+1 for i in added_features]])\n",
    "                feature_index = list(added_features)\n",
    "            # update maximum record\n",
    "            max_accuracy = current_max\n",
    "            print \"Round number: {count_num}, the added feature is: {feature_selected}, maximum score is: {max_acc}\\n\".format(\n",
    "            count_num = count,\n",
    "            feature_selected = feature_name,\n",
    "            max_acc = max_accuracy)\n",
    "        # otherwise, all the results are worse, end the loop\n",
    "        else:\n",
    "            print \"Forward selection ended.\"\n",
    "            print \"Selected features are \",\n",
    "            print final_feature_lst\n",
    "            return feature_index\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_comparison(feature_selected, clf):\n",
    "    X_train_sub = X_train[:,feature_selected]\n",
    "    clf.fit(X_train_sub, y_train)\n",
    "    prediction_train = clf.predict(X_train_sub)\n",
    "    matrix = confusion_matrix(y_train, prediction_train)\n",
    "    train_acc = clf.score(X_train_sub, y_train)\n",
    "    train_auc = roc_auc_score(y_train, prediction_train)\n",
    "    train_fdr = matrix[1,1]/sum(y_train)\n",
    "    \n",
    "    X_test_sub = X_test[:,feature_selected]\n",
    "    prediction_test = clf.predict(X_test_sub)\n",
    "    matrix = confusion_matrix(y_test, prediction_test)\n",
    "    test_acc = clf.score(X_test_sub, y_test)\n",
    "    test_auc = roc_auc_score(y_test, prediction_test)\n",
    "    test_fdr = matrix[1,1]/sum(y_test)\n",
    "    \n",
    "    comparison_df = pd.DataFrame({ \"Accuracy\": [train_acc, test_acc],\n",
    "                                  \"AUC score\": [train_auc, test_auc],\n",
    "                                  \"FDR\": [train_fdr, test_fdr]},\n",
    "                                 index = [\"Training\", \"Testing\"])\n",
    "    return comparison_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gaussian Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting........ Selection criteria is AUC, baseline score is 0\n",
      "Round number: 1, the added feature is: zip_with_merchnum_7, maximum score is: 0.600636287171\n",
      "\n",
      "Round number: 2, the added feature is: card_amount_to_median_28, maximum score is: 0.658679894424\n",
      "\n",
      "Round number: 3, the added feature is: merchant_amount_to_median_28, maximum score is: 0.687871526354\n",
      "\n",
      "Round number: 4, the added feature is: state_with_merchnum_3, maximum score is: 0.748679886665\n",
      "\n",
      "Round number: 5, the added feature is: merchant_frequency_3, maximum score is: 0.788563417208\n",
      "\n",
      "Round number: 6, the added feature is: card_frequency_7, maximum score is: 0.80726741863\n",
      "\n",
      "Round number: 7, the added feature is: merchant_amount_to_avg_7, maximum score is: 0.818728501526\n",
      "\n",
      "Round number: 8, the added feature is: card_frequency_3, maximum score is: 0.827108536924\n",
      "\n",
      "Round number: 9, the added feature is: merchant_amount_to_avg_3, maximum score is: 0.828094403157\n",
      "\n",
      "Forward selection ended.\n",
      "Selected features are  ['zip_with_merchnum_7', 'card_amount_to_median_28', 'merchant_amount_to_median_28', 'state_with_merchnum_3', 'merchant_frequency_3', 'card_frequency_7', 'merchant_amount_to_avg_7', 'card_frequency_3', 'merchant_amount_to_avg_3']\n"
     ]
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "criteria = \"AUC\"\n",
    "NB_features = forward_selection(X_train, y_train, clf, criteria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>FDR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Training</th>\n",
       "      <td>0.828094</td>\n",
       "      <td>0.874154</td>\n",
       "      <td>0.781726</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Testing</th>\n",
       "      <td>0.774275</td>\n",
       "      <td>0.874412</td>\n",
       "      <td>0.673469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          AUC score  Accuracy       FDR\n",
       "Training   0.828094  0.874154  0.781726\n",
       "Testing    0.774275  0.874412  0.673469"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = GaussianNB()\n",
    "test_comparison(NB_features, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Gaussian Naive Bayes** Classifer does moderately well, and does not seem to suffer a lot from overfitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.796346238476\n",
      "\n",
      "\n",
      "[[70346 17980]\n",
      " [   68   227]]\n",
      "\n",
      "\n",
      "FDR is 0.769491525424\n"
     ]
    }
   ],
   "source": [
    "features_sub = df[['zip_with_merchnum_7', 'card_amount_to_median_28', 'merchant_amount_to_median_28', 'state_with_merchnum_3', 'merchant_frequency_3', 'card_frequency_7', 'merchant_amount_to_avg_7', 'card_frequency_3', 'merchant_amount_to_avg_3']]\n",
    "clf = GaussianNB()\n",
    "clf.fit(features_sub, labels)\n",
    "print \"accuracy is\", clf.score(features_sub, labels)\n",
    "prediction = clf.predict(features_sub)\n",
    "matrix = confusion_matrix(labels, prediction)\n",
    "print \"\\n\"\n",
    "print matrix\n",
    "print \"\\n\"\n",
    "print  \"FDR is\", matrix[1,1]/sum(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting........ Selection criteria is AUC, baseline score is 0\n",
      "Round number: 1, the added feature is: zip_with_merchnum_14, maximum score is: 0.56345177665\n",
      "\n",
      "Round number: 2, the added feature is: card_amount_to_median_7, maximum score is: 0.568527918782\n",
      "\n",
      "Round number: 3, the added feature is: card_amount_to_max_3, maximum score is: 0.5786547288\n",
      "\n",
      "Round number: 4, the added feature is: card_amount_to_avg_28, maximum score is: 0.581192799866\n",
      "\n",
      "Round number: 5, the added feature is: state_with_merchnum_7, maximum score is: 0.583730870932\n",
      "\n",
      "Round number: 6, the added feature is: merchnum_per_card_3, maximum score is: 0.583739362347\n",
      "\n",
      "Round number: 7, the added feature is: merchnum_per_card_28, maximum score is: 0.583747853762\n",
      "\n",
      "Round number: 8, the added feature is: card_amount_to_max_7, maximum score is: 0.588823995894\n",
      "\n",
      "Round number: 9, the added feature is: card_amount_to_avg_3, maximum score is: 0.598984771574\n",
      "\n",
      "Round number: 10, the added feature is: merchant_amount_to_avg_3, maximum score is: 0.598984771574\n",
      "\n",
      "Round number: 11, the added feature is: card_amount_to_avg_7, maximum score is: 0.598984771574\n",
      "\n",
      "Round number: 12, the added feature is: merchant_amount_to_total_3, maximum score is: 0.601497368394\n",
      "\n",
      "Round number: 13, the added feature is: zip_with_merchnum_7, maximum score is: 0.601505859809\n",
      "\n",
      "Round number: 14, the added feature is: merchant_amount_to_avg_7, maximum score is: 0.601505859809\n",
      "\n",
      "Round number: 15, the added feature is: merchant_amount_to_total_7, maximum score is: 0.601505859809\n",
      "\n",
      "Round number: 16, the added feature is: card_amount_to_total_3, maximum score is: 0.601505859809\n",
      "\n",
      "Round number: 17, the added feature is: card_amount_to_total_7, maximum score is: 0.601505859809\n",
      "\n",
      "Round number: 18, the added feature is: merchant_amount_to_avg_14, maximum score is: 0.601505859809\n",
      "\n",
      "Round number: 19, the added feature is: merchant_amount_to_avg_28, maximum score is: 0.601505859809\n",
      "\n",
      "Round number: 20, the added feature is: merchant_amount_to_max_28, maximum score is: 0.606565019111\n",
      "\n",
      "Round number: 21, the added feature is: merchant_amount_to_max_14, maximum score is: 0.606573510526\n",
      "\n",
      "Round number: 22, the added feature is: merchant_amount_to_median_28, maximum score is: 0.609094598762\n",
      "\n",
      "Round number: 23, the added feature is: merchant_amount_to_max_3, maximum score is: 0.611607195582\n",
      "\n",
      "Round number: 24, the added feature is: cardnum_per_merch_7, maximum score is: 0.611615686997\n",
      "\n",
      "Round number: 25, the added feature is: card_amount_to_median_14, maximum score is: 0.611615686997\n",
      "\n",
      "Round number: 26, the added feature is: card_amount_to_median_3, maximum score is: 0.614145266648\n",
      "\n",
      "Round number: 27, the added feature is: card_amount_to_avg_14, maximum score is: 0.614145266648\n",
      "\n",
      "Round number: 28, the added feature is: card_amount_to_total_14, maximum score is: 0.616683337714\n",
      "\n",
      "Round number: 29, the added feature is: card_amount_to_max_14, maximum score is: 0.616683337714\n",
      "\n",
      "Round number: 30, the added feature is: merchant_amount_to_median_14, maximum score is: 0.616683337714\n",
      "\n",
      "Round number: 31, the added feature is: merchant_amount_to_total_14, maximum score is: 0.616683337714\n",
      "\n",
      "Round number: 32, the added feature is: zip_with_merchnum_3, maximum score is: 0.616683337714\n",
      "\n",
      "Round number: 33, the added feature is: merchnum_per_card_7, maximum score is: 0.616691829129\n",
      "\n",
      "Round number: 34, the added feature is: merchant_amount_to_median_3, maximum score is: 0.61922140878\n",
      "\n",
      "Round number: 35, the added feature is: state_with_merchnum_14, maximum score is: 0.624255093836\n",
      "\n",
      "Round number: 36, the added feature is: merchant_frequency_14, maximum score is: 0.626818639148\n",
      "\n",
      "Round number: 37, the added feature is: card_frequency_7, maximum score is: 0.636962431996\n",
      "\n",
      "Round number: 38, the added feature is: cardnum_per_merch_3, maximum score is: 0.636970923412\n",
      "\n",
      "Round number: 39, the added feature is: state_with_merchnum_3, maximum score is: 0.636970923412\n",
      "\n",
      "Round number: 40, the added feature is: zip_with_merchnum_28, maximum score is: 0.636970923412\n",
      "\n",
      "Round number: 41, the added feature is: state_with_merchnum_28, maximum score is: 0.636970923412\n",
      "\n",
      "Round number: 42, the added feature is: cardnum_per_merch_14, maximum score is: 0.636970923412\n",
      "\n",
      "Round number: 43, the added feature is: merchant_amount_to_max_7, maximum score is: 0.636970923412\n",
      "\n",
      "Round number: 44, the added feature is: card_frequency_3, maximum score is: 0.636979414827\n",
      "\n",
      "Round number: 45, the added feature is: merchant_amount_to_median_7, maximum score is: 0.636987906242\n",
      "\n",
      "Round number: 46, the added feature is: merchant_frequency_28, maximum score is: 0.636987906242\n",
      "\n",
      "Round number: 47, the added feature is: card_frequency_14, maximum score is: 0.636987906242\n",
      "\n",
      "Round number: 48, the added feature is: card_amount_to_max_28, maximum score is: 0.636987906242\n",
      "\n",
      "Round number: 49, the added feature is: card_amount_to_median_28, maximum score is: 0.636987906242\n",
      "\n",
      "Round number: 50, the added feature is: card_amount_to_total_28, maximum score is: 0.636987906242\n",
      "\n",
      "Forward selection ended.\n",
      "Selected features are  ['zip_with_merchnum_14', 'card_amount_to_median_7', 'card_amount_to_max_3', 'card_amount_to_avg_28', 'state_with_merchnum_7', 'merchnum_per_card_3', 'merchnum_per_card_28', 'card_amount_to_max_7', 'card_amount_to_avg_3', 'merchant_amount_to_avg_3', 'card_amount_to_avg_7', 'merchant_amount_to_total_3', 'zip_with_merchnum_7', 'merchant_amount_to_avg_7', 'merchant_amount_to_total_7', 'card_amount_to_total_3', 'card_amount_to_total_7', 'merchant_amount_to_avg_14', 'merchant_amount_to_avg_28', 'merchant_amount_to_max_28', 'merchant_amount_to_max_14', 'merchant_amount_to_median_28', 'merchant_amount_to_max_3', 'cardnum_per_merch_7', 'card_amount_to_median_14', 'card_amount_to_median_3', 'card_amount_to_avg_14', 'card_amount_to_total_14', 'card_amount_to_max_14', 'merchant_amount_to_median_14', 'merchant_amount_to_total_14', 'zip_with_merchnum_3', 'merchnum_per_card_7', 'merchant_amount_to_median_3', 'state_with_merchnum_14', 'merchant_frequency_14', 'card_frequency_7', 'cardnum_per_merch_3', 'state_with_merchnum_3', 'zip_with_merchnum_28', 'state_with_merchnum_28', 'cardnum_per_merch_14', 'merchant_amount_to_max_7', 'card_frequency_3', 'merchant_amount_to_median_7']\n"
     ]
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "criteria = \"AUC\"\n",
    "LR_features = forward_selection(X_train, y_train, clf, criteria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>FDR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Training</th>\n",
       "      <td>0.636988</td>\n",
       "      <td>0.997444</td>\n",
       "      <td>0.274112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Testing</th>\n",
       "      <td>0.576446</td>\n",
       "      <td>0.997021</td>\n",
       "      <td>0.153061</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          AUC score  Accuracy       FDR\n",
       "Training   0.636988  0.997444  0.274112\n",
       "Testing    0.576446  0.997021  0.153061"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression()\n",
    "test_comparison(LR_features, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression Model** performs poor. Althrough it's accuracy is not very low, it missed many frauds."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.997257986256\n",
      "\n",
      "\n",
      "[[88312    14]\n",
      " [  229    66]]\n",
      "\n",
      "\n",
      "FDR is 0.223728813559\n"
     ]
    }
   ],
   "source": [
    "features_sub = df[['zip_with_merchnum_14', 'card_amount_to_median_7', 'card_amount_to_max_3', 'card_amount_to_avg_28', 'state_with_merchnum_7', 'merchnum_per_card_3', 'merchnum_per_card_28', 'card_amount_to_max_7', 'card_amount_to_avg_3', 'merchant_amount_to_avg_3', 'card_amount_to_avg_7', 'merchant_amount_to_total_3', 'zip_with_merchnum_7', 'merchant_amount_to_avg_7', 'merchant_amount_to_total_7', 'card_amount_to_total_3', 'card_amount_to_total_7', 'merchant_amount_to_avg_14', 'merchant_amount_to_avg_28', 'merchant_amount_to_max_28', 'merchant_amount_to_max_14', 'merchant_amount_to_median_28', 'merchant_amount_to_max_3', 'cardnum_per_merch_7', 'card_amount_to_median_14', 'card_amount_to_median_3', 'card_amount_to_avg_14', 'card_amount_to_total_14', 'card_amount_to_max_14', 'merchant_amount_to_median_14', 'merchant_amount_to_total_14', 'zip_with_merchnum_3', 'merchnum_per_card_7', 'merchant_amount_to_median_3', 'state_with_merchnum_14', 'merchant_frequency_14', 'card_frequency_7', 'cardnum_per_merch_3', 'state_with_merchnum_3', 'zip_with_merchnum_28', 'state_with_merchnum_28', 'cardnum_per_merch_14', 'merchant_amount_to_max_7', 'card_frequency_3', 'merchant_amount_to_median_7']]\n",
    "clf = LogisticRegression()\n",
    "clf.fit(features_sub, labels)\n",
    "print \"accuracy is\", clf.score(features_sub, labels)\n",
    "prediction = clf.predict(features_sub)\n",
    "matrix = confusion_matrix(labels, prediction)\n",
    "print \"\\n\"\n",
    "print matrix\n",
    "print \"\\n\"\n",
    "print  \"FDR is\", matrix[1,1]/sum(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision Tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting........ Selection criteria is AUC, baseline score is 0\n",
      "Round number: 1, the added feature is: merchant_amount_to_avg_28, maximum score is: 0.977157360406\n",
      "\n",
      "Round number: 2, the added feature is: card_amount_to_avg_14, maximum score is: 0.997461928934\n",
      "\n",
      "Round number: 3, the added feature is: card_amount_to_avg_3, maximum score is: 0.997461928934\n",
      "\n",
      "Round number: 4, the added feature is: card_amount_to_max_3, maximum score is: 0.997461928934\n",
      "\n",
      "Round number: 5, the added feature is: card_amount_to_median_3, maximum score is: 0.997461928934\n",
      "\n",
      "Round number: 6, the added feature is: card_amount_to_total_3, maximum score is: 0.997461928934\n",
      "\n",
      "Round number: 7, the added feature is: merchant_amount_to_avg_3, maximum score is: 0.997461928934\n",
      "\n",
      "Round number: 8, the added feature is: merchant_amount_to_max_3, maximum score is: 0.997461928934\n",
      "\n",
      "Round number: 9, the added feature is: merchant_amount_to_median_3, maximum score is: 0.997461928934\n",
      "\n",
      "Round number: 10, the added feature is: merchant_amount_to_total_3, maximum score is: 0.997461928934\n",
      "\n",
      "Round number: 11, the added feature is: card_amount_to_avg_7, maximum score is: 0.997461928934\n",
      "\n",
      "Round number: 12, the added feature is: card_amount_to_max_7, maximum score is: 0.997461928934\n",
      "\n",
      "Round number: 13, the added feature is: card_amount_to_median_7, maximum score is: 0.997461928934\n",
      "\n",
      "Round number: 14, the added feature is: card_amount_to_total_7, maximum score is: 0.997461928934\n",
      "\n",
      "Round number: 15, the added feature is: merchant_amount_to_avg_7, maximum score is: 0.997461928934\n",
      "\n",
      "Round number: 16, the added feature is: merchant_amount_to_max_7, maximum score is: 0.997461928934\n",
      "\n",
      "Round number: 17, the added feature is: merchant_amount_to_median_7, maximum score is: 0.997461928934\n",
      "\n",
      "Round number: 18, the added feature is: merchant_amount_to_total_7, maximum score is: 0.997461928934\n",
      "\n",
      "Round number: 19, the added feature is: card_amount_to_max_14, maximum score is: 0.997461928934\n",
      "\n",
      "Round number: 20, the added feature is: card_amount_to_median_14, maximum score is: 0.997461928934\n",
      "\n",
      "Round number: 21, the added feature is: card_amount_to_total_14, maximum score is: 0.997461928934\n",
      "\n",
      "Round number: 22, the added feature is: merchant_amount_to_avg_14, maximum score is: 0.997461928934\n",
      "\n",
      "Round number: 23, the added feature is: merchant_amount_to_max_14, maximum score is: 0.997461928934\n",
      "\n",
      "Round number: 24, the added feature is: merchant_amount_to_median_14, maximum score is: 0.997461928934\n",
      "\n",
      "Round number: 25, the added feature is: merchant_amount_to_total_14, maximum score is: 0.997461928934\n",
      "\n",
      "Round number: 26, the added feature is: card_amount_to_avg_28, maximum score is: 0.997461928934\n",
      "\n",
      "Round number: 27, the added feature is: card_amount_to_max_28, maximum score is: 0.997461928934\n",
      "\n",
      "Round number: 28, the added feature is: card_amount_to_median_28, maximum score is: 0.997461928934\n",
      "\n",
      "Round number: 29, the added feature is: card_amount_to_total_28, maximum score is: 0.997461928934\n",
      "\n",
      "Round number: 30, the added feature is: merchant_amount_to_max_28, maximum score is: 0.997461928934\n",
      "\n",
      "Round number: 31, the added feature is: merchant_amount_to_median_28, maximum score is: 0.997461928934\n",
      "\n",
      "Round number: 32, the added feature is: merchant_amount_to_total_28, maximum score is: 0.997461928934\n",
      "\n",
      "Round number: 33, the added feature is: merchDaily, maximum score is: 0.997461928934\n",
      "\n",
      "Round number: 34, the added feature is: merchLag3Cum, maximum score is: 0.997461928934\n",
      "\n",
      "Round number: 35, the added feature is: merchLag7Cum, maximum score is: 0.997461928934\n",
      "\n",
      "Round number: 36, the added feature is: merchLag14Cum, maximum score is: 0.997461928934\n",
      "\n",
      "Round number: 37, the added feature is: merchLag28Cum, maximum score is: 0.997461928934\n",
      "\n",
      "Round number: 38, the added feature is: cardDaily, maximum score is: 0.997461928934\n",
      "\n",
      "Round number: 39, the added feature is: cardLag3Cum, maximum score is: 0.997461928934\n",
      "\n",
      "Round number: 40, the added feature is: cardLag7Cum, maximum score is: 0.997461928934\n",
      "\n",
      "Round number: 41, the added feature is: cardLag14Cum, maximum score is: 0.997461928934\n",
      "\n",
      "Round number: 42, the added feature is: cardLag28Cum, maximum score is: 0.997461928934\n",
      "\n",
      "Round number: 43, the added feature is: zip_with_merchnum_3, maximum score is: 0.997461928934\n",
      "\n",
      "Round number: 44, the added feature is: state_with_merchnum_3, maximum score is: 0.997461928934\n",
      "\n",
      "Round number: 45, the added feature is: zip_with_merchnum_7, maximum score is: 0.997461928934\n",
      "\n",
      "Round number: 46, the added feature is: state_with_merchnum_7, maximum score is: 0.997461928934\n",
      "\n",
      "Round number: 47, the added feature is: cardnum_per_merch_3, maximum score is: 0.997461928934\n",
      "\n",
      "Round number: 48, the added feature is: cardnum_per_merch_7, maximum score is: 0.997461928934\n",
      "\n",
      "Round number: 49, the added feature is: merchnum_per_card_3, maximum score is: 0.997461928934\n",
      "\n",
      "Round number: 50, the added feature is: merchnum_per_card_7, maximum score is: 0.997461928934\n",
      "\n",
      "Round number: 51, the added feature is: zip_with_merchnum_14, maximum score is: 0.997461928934\n",
      "\n",
      "Round number: 52, the added feature is: state_with_merchnum_14, maximum score is: 0.997461928934\n",
      "\n",
      "Round number: 53, the added feature is: zip_with_merchnum_28, maximum score is: 0.997461928934\n",
      "\n",
      "Round number: 54, the added feature is: merchnum_per_card_14, maximum score is: 0.997461928934\n",
      "\n",
      "Round number: 55, the added feature is: merchnum_per_card_28, maximum score is: 0.997461928934\n",
      "\n",
      "Round number: 56, the added feature is: state_with_merchnum_28, maximum score is: 0.997461928934\n",
      "\n",
      "Round number: 57, the added feature is: cardnum_per_merch_14, maximum score is: 0.997461928934\n",
      "\n",
      "Round number: 58, the added feature is: cardnum_per_merch_28, maximum score is: 0.997461928934\n",
      "\n",
      "Forward selection ended.\n",
      "Selected features are  ['merchant_amount_to_avg_28', 'card_amount_to_avg_14']\n"
     ]
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "criteria = \"AUC\"\n",
    "DT_features = forward_selection(X_train, y_train, clf, criteria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>FDR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Training</th>\n",
       "      <td>0.997462</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.994924</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Testing</th>\n",
       "      <td>0.502979</td>\n",
       "      <td>0.992485</td>\n",
       "      <td>0.010204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          AUC score  Accuracy       FDR\n",
       "Training   0.997462  0.999983  0.994924\n",
       "Testing    0.502979  0.992485  0.010204"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = DecisionTreeClassifier()\n",
    "test_comparison(DT_features, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Single Decision Tree Classsifier** gives extremely overfitted output..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting........ Selection criteria is AUC, baseline score is 0\n",
      "Round number: 1, the added feature is: merchant_amount_to_max_28, maximum score is: 0.883189291058\n",
      "\n",
      "Round number: 2, the added feature is: merchant_frequency_3, maximum score is: 0.888316381681\n",
      "\n",
      "Round number: 3, the added feature is: card_amount_to_total_14, maximum score is: 0.931472081218\n",
      "\n",
      "Round number: 4, the added feature is: zip_with_merchnum_3, maximum score is: 0.936539731935\n",
      "\n",
      "Round number: 5, the added feature is: card_frequency_7, maximum score is: 0.94923857868\n",
      "\n",
      "Round number: 6, the added feature is: merchant_amount_to_median_7, maximum score is: 0.956852791878\n",
      "\n",
      "Round number: 7, the added feature is: merchnum_per_card_7, maximum score is: 0.959390862944\n",
      "\n",
      "Round number: 8, the added feature is: merchnum_per_card_28, maximum score is: 0.972081218274\n",
      "\n",
      "Forward selection ended.\n",
      "Selected features are  ['merchant_amount_to_max_28', 'merchant_frequency_3', 'card_amount_to_total_14', 'zip_with_merchnum_3', 'card_frequency_7', 'merchant_amount_to_median_7', 'merchnum_per_card_7', 'merchnum_per_card_28']\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_jobs = 3)\n",
    "criteria = \"AUC\"\n",
    "RF_features = forward_selection(X_train, y_train, clf, criteria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>FDR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Training</th>\n",
       "      <td>0.931472</td>\n",
       "      <td>0.999543</td>\n",
       "      <td>0.862944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Testing</th>\n",
       "      <td>0.642823</td>\n",
       "      <td>0.997563</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          AUC score  Accuracy       FDR\n",
       "Training   0.931472  0.999543  0.862944\n",
       "Testing    0.642823  0.997563  0.285714"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_jobs = 3)\n",
    "test_comparison(RF_features, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest** with default setting overally performs well, althrough still suffers from overfitting to some extent."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting........ Selection criteria is AUC, baseline score is 0\n",
      "Round number: 1, the added feature is: merchant_amount_to_median_28, maximum score is: 0.857851037474\n",
      "\n",
      "Round number: 2, the added feature is: merchant_amount_to_avg_3, maximum score is: 0.888290907436\n",
      "\n",
      "Round number: 3, the added feature is: merchnum_per_card_14, maximum score is: 0.895896629219\n",
      "\n",
      "Round number: 4, the added feature is: card_frequency_14, maximum score is: 0.906082879143\n",
      "\n",
      "Round number: 5, the added feature is: zip_with_merchnum_28, maximum score is: 0.926395939086\n",
      "\n",
      "Round number: 6, the added feature is: merchant_amount_to_max_14, maximum score is: 0.944162436548\n",
      "\n",
      "Round number: 7, the added feature is: cardnum_per_merch_3, maximum score is: 0.946692016199\n",
      "\n",
      "Round number: 8, the added feature is: card_amount_to_max_14, maximum score is: 0.946700507614\n",
      "\n",
      "Round number: 9, the added feature is: merchant_amount_to_median_14, maximum score is: 0.964467005076\n",
      "\n",
      "Forward selection ended.\n",
      "Selected features are  ['merchant_amount_to_median_28', 'merchant_amount_to_avg_3', 'merchnum_per_card_14', 'card_frequency_14', 'zip_with_merchnum_28', 'merchant_amount_to_max_14', 'cardnum_per_merch_3', 'card_amount_to_max_14', 'merchant_amount_to_median_14']\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators = 20, max_depth = 20, min_samples_split = 5, random_state = 42, n_jobs = 3)\n",
    "criteria = \"AUC\"\n",
    "RF_features = forward_selection(X_train, y_train, clf, criteria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>FDR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Training</th>\n",
       "      <td>0.964467</td>\n",
       "      <td>0.999763</td>\n",
       "      <td>0.928934</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Testing</th>\n",
       "      <td>0.678571</td>\n",
       "      <td>0.997867</td>\n",
       "      <td>0.357143</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          AUC score  Accuracy       FDR\n",
       "Training   0.964467  0.999763  0.928934\n",
       "Testing    0.678571  0.997867  0.357143"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators = 20, max_depth = 20, min_samples_split = 5, random_state = 42, n_jobs = 3)\n",
    "test_comparison(RF_features, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting........ Selection criteria is AUC, baseline score is 0\n",
      "Round number: 1, the added feature is: zip_with_merchnum_14, maximum score is: 0.56345177665\n",
      "\n",
      "Round number: 2, the added feature is: merchant_amount_to_max_7, maximum score is: 0.601480385564\n",
      "\n",
      "Round number: 3, the added feature is: cardnum_per_merch_28, maximum score is: 0.626869587639\n",
      "\n",
      "Round number: 4, the added feature is: merchant_frequency_28, maximum score is: 0.725845867797\n",
      "\n",
      "Round number: 5, the added feature is: card_amount_to_median_28, maximum score is: 0.74364633092\n",
      "\n",
      "Round number: 6, the added feature is: merchnum_per_card_14, maximum score is: 0.758883248731\n",
      "\n",
      "Round number: 7, the added feature is: card_frequency_7, maximum score is: 0.784263959391\n",
      "\n",
      "Round number: 8, the added feature is: cardnum_per_merch_14, maximum score is: 0.796954314721\n",
      "\n",
      "Round number: 9, the added feature is: merchant_amount_to_median_28, maximum score is: 0.812182741117\n",
      "\n",
      "Round number: 10, the added feature is: cardnum_per_merch_7, maximum score is: 0.822335025381\n",
      "\n",
      "Round number: 11, the added feature is: merchant_amount_to_total_28, maximum score is: 0.822335025381\n",
      "\n",
      "Round number: 12, the added feature is: state_with_merchnum_3, maximum score is: 0.822335025381\n",
      "\n",
      "Forward selection ended.\n",
      "Selected features are  ['zip_with_merchnum_14', 'merchant_amount_to_max_7', 'cardnum_per_merch_28', 'merchant_frequency_28', 'card_amount_to_median_28', 'merchnum_per_card_14', 'card_frequency_7', 'cardnum_per_merch_14', 'merchant_amount_to_median_28', 'cardnum_per_merch_7']\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators = 20, max_depth = 20, min_samples_leaf = 5, random_state = 42, n_jobs = 3)\n",
    "criteria = \"AUC\"\n",
    "RF_features = forward_selection(X_train, y_train, clf, criteria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>FDR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Training</th>\n",
       "      <td>0.822335</td>\n",
       "      <td>0.998815</td>\n",
       "      <td>0.644670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Testing</th>\n",
       "      <td>0.719371</td>\n",
       "      <td>0.998104</td>\n",
       "      <td>0.438776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          AUC score  Accuracy       FDR\n",
       "Training   0.822335  0.998815  0.644670\n",
       "Testing    0.719371  0.998104  0.438776"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators = 20, max_depth = 20, min_samples_leaf = 5, random_state = 42, n_jobs = 3)\n",
    "test_comparison(RF_features, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting........ Selection criteria is AUC, baseline score is 0\n",
      "Round number: 1, the added feature is: zip_with_merchnum_14, maximum score is: 0.56345177665\n",
      "\n",
      "Round number: 2, the added feature is: merchant_amount_to_max_7, maximum score is: 0.601497368394\n",
      "\n",
      "Round number: 3, the added feature is: cardnum_per_merch_28, maximum score is: 0.626878079054\n",
      "\n",
      "Round number: 4, the added feature is: merchant_frequency_28, maximum score is: 0.725845867797\n",
      "\n",
      "Round number: 5, the added feature is: merchnum_per_card_28, maximum score is: 0.751243561287\n",
      "\n",
      "Round number: 6, the added feature is: card_frequency_3, maximum score is: 0.781725888325\n",
      "\n",
      "Round number: 7, the added feature is: card_amount_to_median_28, maximum score is: 0.791878172589\n",
      "\n",
      "Round number: 8, the added feature is: merchant_amount_to_max_28, maximum score is: 0.794416243655\n",
      "\n",
      "Round number: 9, the added feature is: merchant_frequency_14, maximum score is: 0.814720812183\n",
      "\n",
      "Forward selection ended.\n",
      "Selected features are  ['zip_with_merchnum_14', 'merchant_amount_to_max_7', 'cardnum_per_merch_28', 'merchant_frequency_28', 'merchnum_per_card_28', 'card_frequency_3', 'card_amount_to_median_28', 'merchant_amount_to_max_28', 'merchant_frequency_14']\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators = 25, max_depth = 20, min_samples_leaf = 5, random_state = 42, n_jobs = 3)\n",
    "criteria = \"AUC\"\n",
    "RF_features = forward_selection(X_train, y_train, clf, criteria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>FDR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Training</th>\n",
       "      <td>0.814721</td>\n",
       "      <td>0.998764</td>\n",
       "      <td>0.629442</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Testing</th>\n",
       "      <td>0.719388</td>\n",
       "      <td>0.998138</td>\n",
       "      <td>0.438776</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          AUC score  Accuracy       FDR\n",
       "Training   0.814721  0.998764  0.629442\n",
       "Testing    0.719388  0.998138  0.438776"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators = 25, max_depth = 20, min_samples_leaf = 5, random_state = 42, n_jobs = 3)\n",
    "test_comparison(RF_features, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tunned a little bit, and FDR on testing data improved."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.99860078311\n",
      "\n",
      "\n",
      "[[88326     0]\n",
      " [  124   171]]\n",
      "\n",
      "\n",
      "FDR is 0.579661016949\n"
     ]
    }
   ],
   "source": [
    "features_sub = df[['zip_with_merchnum_14', 'merchant_amount_to_max_7', 'cardnum_per_merch_28', 'merchant_frequency_28', 'merchnum_per_card_28', 'card_frequency_3', 'card_amount_to_median_28', 'merchant_amount_to_max_28', 'merchant_frequency_14']]\n",
    "clf = RandomForestClassifier(n_estimators = 25, max_depth = 20, min_samples_leaf = 5, random_state = 42, n_jobs = 3)\n",
    "clf.fit(features_sub, labels)\n",
    "print \"accuracy is\", clf.score(features_sub, labels)\n",
    "prediction = clf.predict(features_sub)\n",
    "matrix = confusion_matrix(labels, prediction)\n",
    "print \"\\n\"\n",
    "print matrix\n",
    "print \"\\n\"\n",
    "print  \"FDR is\", matrix[1,1]/sum(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting........ Selection criteria is AUC, baseline score is 0\n",
      "Round number: 1, the added feature is: zip_with_merchnum_14, maximum score is: 0.56345177665\n",
      "\n",
      "Round number: 2, the added feature is: card_amount_to_median_7, maximum score is: 0.568527918782\n",
      "\n",
      "Round number: 3, the added feature is: card_frequency_7, maximum score is: 0.614196215139\n",
      "\n",
      "Round number: 4, the added feature is: merchnum_per_card_28, maximum score is: 0.619280848686\n",
      "\n",
      "Round number: 5, the added feature is: card_amount_to_max_14, maximum score is: 0.621818919752\n",
      "\n",
      "Round number: 6, the added feature is: merchant_amount_to_avg_14, maximum score is: 0.624356990818\n",
      "\n",
      "Round number: 7, the added feature is: merchant_amount_to_median_3, maximum score is: 0.631971204016\n",
      "\n",
      "Round number: 8, the added feature is: merchant_amount_to_median_28, maximum score is: 0.670042270006\n",
      "\n",
      "Round number: 9, the added feature is: merchant_amount_to_median_14, maximum score is: 0.682732625336\n",
      "\n",
      "Round number: 10, the added feature is: merchant_amount_to_avg_28, maximum score is: 0.687808767468\n",
      "\n",
      "Round number: 11, the added feature is: merchant_amount_to_avg_7, maximum score is: 0.690346838534\n",
      "\n",
      "Round number: 12, the added feature is: cardnum_per_merch_28, maximum score is: 0.695422980666\n",
      "\n",
      "Round number: 13, the added feature is: cardnum_per_merch_7, maximum score is: 0.700499122798\n",
      "\n",
      "Round number: 14, the added feature is: merchant_amount_to_avg_3, maximum score is: 0.700499122798\n",
      "\n",
      "Round number: 15, the added feature is: zip_with_merchnum_3, maximum score is: 0.703037193864\n",
      "\n",
      "Forward selection ended.\n",
      "Selected features are  ['zip_with_merchnum_14', 'card_amount_to_median_7', 'card_frequency_7', 'merchnum_per_card_28', 'card_amount_to_max_14', 'merchant_amount_to_avg_14', 'merchant_amount_to_median_3', 'merchant_amount_to_median_28', 'merchant_amount_to_median_14', 'merchant_amount_to_avg_28', 'merchant_amount_to_avg_7', 'cardnum_per_merch_28', 'cardnum_per_merch_7', 'merchant_amount_to_avg_3', 'zip_with_merchnum_3']\n"
     ]
    }
   ],
   "source": [
    "clf = SVC()\n",
    "criteria = \"AUC\"\n",
    "SVM_features = forward_selection(X_train, y_train, clf, criteria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>FDR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Training</th>\n",
       "      <td>0.703037</td>\n",
       "      <td>0.998003</td>\n",
       "      <td>0.406091</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Testing</th>\n",
       "      <td>0.591820</td>\n",
       "      <td>0.997258</td>\n",
       "      <td>0.183673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          AUC score  Accuracy       FDR\n",
       "Training   0.703037  0.998003  0.406091\n",
       "Testing    0.591820  0.997258  0.183673"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = SVC()\n",
    "test_comparison(SVM_features, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SVM** performs moderatelly well. Not much overfitting seen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.997901174665\n",
      "\n",
      "\n",
      "[[88324     2]\n",
      " [  184   111]]\n",
      "\n",
      "\n",
      "FDR is 0.376271186441\n"
     ]
    }
   ],
   "source": [
    "features_sub = df[['zip_with_merchnum_14', 'card_amount_to_median_7', 'card_frequency_7', 'merchnum_per_card_28', 'card_amount_to_max_14', 'merchant_amount_to_avg_14', 'merchant_amount_to_median_3', 'merchant_amount_to_median_28', 'merchant_amount_to_median_14', 'merchant_amount_to_avg_28', 'merchant_amount_to_avg_7', 'cardnum_per_merch_28', 'cardnum_per_merch_7', 'merchant_amount_to_avg_3', 'zip_with_merchnum_3']]\n",
    "clf = SVC()\n",
    "clf.fit(features_sub, labels)\n",
    "print \"accuracy is\", clf.score(features_sub, labels)\n",
    "prediction = clf.predict(features_sub)\n",
    "matrix = confusion_matrix(labels, prediction)\n",
    "print \"\\n\"\n",
    "print matrix\n",
    "print \"\\n\"\n",
    "print  \"FDR is\", matrix[1,1]/sum(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network (Multi-Layer Perceptron Classifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting........ Selection criteria is AUC, baseline score is 0\n",
      "Round number: 1, the added feature is: zip_with_merchnum_28, maximum score is: 0.540609137056\n",
      "\n",
      "Round number: 2, the added feature is: state_with_merchnum_14, maximum score is: 0.55076142132\n",
      "\n",
      "Round number: 3, the added feature is: merchant_amount_to_avg_7, maximum score is: 0.555837563452\n",
      "\n",
      "Round number: 4, the added feature is: card_amount_to_median_28, maximum score is: 0.560913705584\n",
      "\n",
      "Round number: 5, the added feature is: zip_with_merchnum_14, maximum score is: 0.56345177665\n",
      "\n",
      "Round number: 6, the added feature is: merchant_amount_to_median_28, maximum score is: 0.56345177665\n",
      "\n",
      "Round number: 7, the added feature is: card_frequency_7, maximum score is: 0.57614213198\n",
      "\n",
      "Round number: 8, the added feature is: cardnum_per_merch_7, maximum score is: 0.647165664752\n",
      "\n",
      "Round number: 9, the added feature is: merchnum_per_card_14, maximum score is: 0.692791504033\n",
      "\n",
      "Round number: 10, the added feature is: merchant_amount_to_median_3, maximum score is: 0.713138529637\n",
      "\n",
      "Round number: 11, the added feature is: merchant_amount_to_total_28, maximum score is: 0.730905027099\n",
      "\n",
      "Round number: 12, the added feature is: card_amount_to_max_14, maximum score is: 0.730913518514\n",
      "\n",
      "Round number: 13, the added feature is: merchant_amount_to_max_28, maximum score is: 0.730922009929\n",
      "\n",
      "Round number: 14, the added feature is: cardnum_per_merch_3, maximum score is: 0.730922009929\n",
      "\n",
      "Round number: 15, the added feature is: merchant_amount_to_avg_28, maximum score is: 0.741057311363\n",
      "\n",
      "Round number: 16, the added feature is: merchnum_per_card_28, maximum score is: 0.751218087042\n",
      "\n",
      "Round number: 17, the added feature is: merchnum_per_card_3, maximum score is: 0.756285737759\n",
      "\n",
      "Round number: 18, the added feature is: card_amount_to_avg_28, maximum score is: 0.761378862721\n",
      "\n",
      "Round number: 19, the added feature is: card_amount_to_avg_3, maximum score is: 0.769001567334\n",
      "\n",
      "Forward selection ended.\n",
      "Selected features are  ['zip_with_merchnum_28', 'state_with_merchnum_14', 'merchant_amount_to_avg_7', 'card_amount_to_median_28', 'zip_with_merchnum_14', 'merchant_amount_to_median_28', 'card_frequency_7', 'cardnum_per_merch_7', 'merchnum_per_card_14', 'merchant_amount_to_median_3', 'merchant_amount_to_total_28', 'card_amount_to_max_14', 'merchant_amount_to_max_28', 'cardnum_per_merch_3', 'merchant_amount_to_avg_28', 'merchnum_per_card_28', 'merchnum_per_card_3', 'card_amount_to_avg_28', 'card_amount_to_avg_3']\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(activation = \"logistic\")\n",
    "criteria = \"AUC\"\n",
    "NN_features = forward_selection(X_train, y_train, clf, criteria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>FDR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Training</th>\n",
       "      <td>0.768976</td>\n",
       "      <td>0.998341</td>\n",
       "      <td>0.538071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Testing</th>\n",
       "      <td>0.698946</td>\n",
       "      <td>0.997935</td>\n",
       "      <td>0.397959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          AUC score  Accuracy       FDR\n",
       "Training   0.768976  0.998341  0.538071\n",
       "Testing    0.698946  0.997935  0.397959"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPClassifier()\n",
    "test_comparison(NN_features, clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting........ Selection criteria is AUC, baseline score is 0\n",
      "Round number: 1, the added feature is: zip_with_merchnum_14, maximum score is: 0.56345177665\n",
      "\n",
      "Round number: 2, the added feature is: card_amount_to_median_3, maximum score is: 0.565989847716\n",
      "\n",
      "Round number: 3, the added feature is: merchant_amount_to_avg_28, maximum score is: 0.570887670129\n",
      "\n",
      "Round number: 4, the added feature is: card_amount_to_median_14, maximum score is: 0.588730590327\n",
      "\n",
      "Round number: 5, the added feature is: merchant_frequency_3, maximum score is: 0.616547475071\n",
      "\n",
      "Round number: 6, the added feature is: card_frequency_3, maximum score is: 0.657343423261\n",
      "\n",
      "Round number: 7, the added feature is: merchnum_per_card_7, maximum score is: 0.70808786175\n",
      "\n",
      "Round number: 8, the added feature is: cardnum_per_merch_14, maximum score is: 0.743612365259\n",
      "\n",
      "Round number: 9, the added feature is: merchnum_per_card_3, maximum score is: 0.766455004853\n",
      "\n",
      "Round number: 10, the added feature is: cardnum_per_merch_28, maximum score is: 0.77403525239\n",
      "\n",
      "Round number: 11, the added feature is: merchant_frequency_28, maximum score is: 0.799432945881\n",
      "\n",
      "Round number: 12, the added feature is: merchant_amount_to_median_3, maximum score is: 0.802004982607\n",
      "\n",
      "Round number: 13, the added feature is: card_amount_to_max_14, maximum score is: 0.816995649378\n",
      "\n",
      "Forward selection ended.\n",
      "Selected features are  ['zip_with_merchnum_14', 'card_amount_to_median_3', 'merchant_amount_to_avg_28', 'card_amount_to_median_14', 'merchant_frequency_3', 'card_frequency_3', 'merchnum_per_card_7', 'cardnum_per_merch_14', 'merchnum_per_card_3', 'cardnum_per_merch_28', 'merchant_frequency_28', 'merchant_amount_to_median_3', 'card_amount_to_max_14']\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier()\n",
    "criteria = \"AUC\"\n",
    "NN_features = forward_selection(X_train, y_train, clf, criteria)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AUC score</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>FDR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Training</th>\n",
       "      <td>0.789298</td>\n",
       "      <td>0.998510</td>\n",
       "      <td>0.578680</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Testing</th>\n",
       "      <td>0.704014</td>\n",
       "      <td>0.997901</td>\n",
       "      <td>0.408163</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          AUC score  Accuracy       FDR\n",
       "Training   0.789298  0.998510  0.578680\n",
       "Testing    0.704014  0.997901  0.408163"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = MLPClassifier()\n",
    "test_comparison(NN_features, clf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Neural Network** performs quite impressive compared to other models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 0.998420238995\n",
      "\n",
      "\n",
      "[[88308    18]\n",
      " [  122   173]]\n",
      "\n",
      "\n",
      "FDR is 0.586440677966\n",
      "Number of Layers is 3\n"
     ]
    }
   ],
   "source": [
    "features_sub = df[['zip_with_merchnum_14', 'card_amount_to_median_3', 'merchant_amount_to_avg_28', 'card_amount_to_median_14', 'merchant_frequency_3', 'card_frequency_3', 'merchnum_per_card_7', 'cardnum_per_merch_14', 'merchnum_per_card_3', 'cardnum_per_merch_28', 'merchant_frequency_28', 'merchant_amount_to_median_3', 'card_amount_to_max_14']]\n",
    "clf = MLPClassifier()\n",
    "clf.fit(features_sub, labels)\n",
    "print \"accuracy is\", clf.score(features_sub, labels)\n",
    "prediction = clf.predict(features_sub)\n",
    "matrix = confusion_matrix(labels, prediction)\n",
    "print \"\\n\"\n",
    "print matrix\n",
    "print \"\\n\"\n",
    "print  \"FDR is\", matrix[1,1]/sum(labels)\n",
    "print \"Number of Layers is\", clf.n_layers_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NB\n",
    "features_sub = df[['zip_with_merchnum_7', 'card_amount_to_median_28', 'merchant_amount_to_median_28', 'state_with_merchnum_3', 'merchant_frequency_3', 'card_frequency_7', 'merchant_amount_to_avg_7', 'card_frequency_3', 'merchant_amount_to_avg_3']]\n",
    "clf = GaussianNB()\n",
    "clf.fit(features_sub, labels)\n",
    "NB_scores = clf.predict_proba(features_sub)[:,1]\n",
    "NB_scores_df = pd.DataFrame({\"NB\": NB_scores})\n",
    "\n",
    "# LR\n",
    "features_sub = df[['zip_with_merchnum_14', 'card_amount_to_median_7', 'card_amount_to_max_3', 'card_amount_to_avg_28', 'state_with_merchnum_7', 'merchnum_per_card_3', 'merchnum_per_card_28', 'card_amount_to_max_7', 'card_amount_to_avg_3', 'merchant_amount_to_avg_3', 'card_amount_to_avg_7', 'merchant_amount_to_total_3', 'zip_with_merchnum_7', 'merchant_amount_to_avg_7', 'merchant_amount_to_total_7', 'card_amount_to_total_3', 'card_amount_to_total_7', 'merchant_amount_to_avg_14', 'merchant_amount_to_avg_28', 'merchant_amount_to_max_28', 'merchant_amount_to_max_14', 'merchant_amount_to_median_28', 'merchant_amount_to_max_3', 'cardnum_per_merch_7', 'card_amount_to_median_14', 'card_amount_to_median_3', 'card_amount_to_avg_14', 'card_amount_to_total_14', 'card_amount_to_max_14', 'merchant_amount_to_median_14', 'merchant_amount_to_total_14', 'zip_with_merchnum_3', 'merchnum_per_card_7', 'merchant_amount_to_median_3', 'state_with_merchnum_14', 'merchant_frequency_14', 'card_frequency_7', 'cardnum_per_merch_3', 'state_with_merchnum_3', 'zip_with_merchnum_28', 'state_with_merchnum_28', 'cardnum_per_merch_14', 'merchant_amount_to_max_7', 'card_frequency_3', 'merchant_amount_to_median_7']]\n",
    "clf = LogisticRegression()\n",
    "clf.fit(features_sub, labels)\n",
    "LR_scores = clf.predict_proba(features_sub)[:,1]\n",
    "LR_scores_df = pd.DataFrame({\"LR\": LR_scores})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# RF\n",
    "features_sub = df[['zip_with_merchnum_14', 'merchant_amount_to_max_7', 'cardnum_per_merch_28', 'merchant_frequency_28', 'merchnum_per_card_28', 'card_frequency_3', 'card_amount_to_median_28', 'merchant_amount_to_max_28', 'merchant_frequency_14']]\n",
    "clf = RandomForestClassifier(n_estimators = 25, max_depth = 20, min_samples_leaf = 5, random_state = 42, n_jobs = 3)\n",
    "clf.fit(features_sub, labels)\n",
    "RF_scores = clf.predict_proba(features_sub)[:,1]\n",
    "RF_scores_df = pd.DataFrame({\"RF\": RF_scores})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# SVM\n",
    "features_sub = df[['zip_with_merchnum_14', 'card_amount_to_median_7', 'card_frequency_7', 'merchnum_per_card_28', 'card_amount_to_max_14', 'merchant_amount_to_avg_14', 'merchant_amount_to_median_3', 'merchant_amount_to_median_28', 'merchant_amount_to_median_14', 'merchant_amount_to_avg_28', 'merchant_amount_to_avg_7', 'cardnum_per_merch_28', 'cardnum_per_merch_7', 'merchant_amount_to_avg_3', 'zip_with_merchnum_3']]\n",
    "clf = SVC()\n",
    "clf.fit(features_sub, labels)\n",
    "SVM_scores = clf.predict(features_sub)\n",
    "SVM_scores_df = pd.DataFrame({\"SVM\": SVM_scores})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# NN\n",
    "features_sub = df[['zip_with_merchnum_14', 'card_amount_to_median_3', 'merchant_amount_to_avg_28', 'card_amount_to_median_14', 'merchant_frequency_3', 'card_frequency_3', 'merchnum_per_card_7', 'cardnum_per_merch_14', 'merchnum_per_card_3', 'cardnum_per_merch_28', 'merchant_frequency_28', 'merchant_amount_to_median_3', 'card_amount_to_max_14']]\n",
    "clf = MLPClassifier()\n",
    "clf.fit(features_sub, labels)\n",
    "NN_scores = clf.predict_proba(features_sub)[:,1]\n",
    "NN_scores_df = pd.DataFrame({\"NN\": NN_scores})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score_df = pd.concat([NB_scores_df, LR_scores_df, RF_scores_df, SVM_scores_df, NN_scores_df], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "score_df.index = df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NB</th>\n",
       "      <th>LR</th>\n",
       "      <th>RF</th>\n",
       "      <th>SVM</th>\n",
       "      <th>NN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6387</th>\n",
       "      <td>3.404842e-01</td>\n",
       "      <td>3.921922e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.472640e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6388</th>\n",
       "      <td>3.613225e-01</td>\n",
       "      <td>1.070882e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.669514e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6389</th>\n",
       "      <td>3.809107e-01</td>\n",
       "      <td>2.090709e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.467624e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6390</th>\n",
       "      <td>3.525849e-01</td>\n",
       "      <td>1.606118e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.360208e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6391</th>\n",
       "      <td>4.651333e-01</td>\n",
       "      <td>3.153660e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.142533e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6392</th>\n",
       "      <td>9.754979e-15</td>\n",
       "      <td>2.190598e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.461036e-14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6393</th>\n",
       "      <td>4.511036e-15</td>\n",
       "      <td>2.288421e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.438351e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6394</th>\n",
       "      <td>1.437577e-15</td>\n",
       "      <td>7.475549e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.706684e-15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6395</th>\n",
       "      <td>3.162768e-01</td>\n",
       "      <td>2.150531e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.594412e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6396</th>\n",
       "      <td>3.311566e-01</td>\n",
       "      <td>6.061353e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.814273e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6397</th>\n",
       "      <td>3.551827e-01</td>\n",
       "      <td>1.564069e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.165430e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6398</th>\n",
       "      <td>1.264752e-15</td>\n",
       "      <td>4.560757e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.060509e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6399</th>\n",
       "      <td>5.288710e-16</td>\n",
       "      <td>4.708565e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.530897e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6400</th>\n",
       "      <td>2.194818e-16</td>\n",
       "      <td>4.880651e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.987091e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6401</th>\n",
       "      <td>8.932326e-17</td>\n",
       "      <td>5.061068e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.512578e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6402</th>\n",
       "      <td>3.380293e-17</td>\n",
       "      <td>4.948354e-06</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.302998e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6403</th>\n",
       "      <td>1.342473e-17</td>\n",
       "      <td>5.188557e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.865801e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6404</th>\n",
       "      <td>5.219947e-18</td>\n",
       "      <td>5.444968e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.681377e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6405</th>\n",
       "      <td>1.985910e-18</td>\n",
       "      <td>5.702241e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.697039e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6406</th>\n",
       "      <td>7.401824e-19</td>\n",
       "      <td>5.973035e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.994347e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6407</th>\n",
       "      <td>2.701015e-19</td>\n",
       "      <td>6.259274e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.387325e-12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6408</th>\n",
       "      <td>4.589283e-01</td>\n",
       "      <td>1.188628e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.437423e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6409</th>\n",
       "      <td>4.184343e-01</td>\n",
       "      <td>2.814571e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.045322e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6410</th>\n",
       "      <td>4.466624e-01</td>\n",
       "      <td>3.829563e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.750931e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6411</th>\n",
       "      <td>4.139319e-01</td>\n",
       "      <td>1.223270e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.136301e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6412</th>\n",
       "      <td>1.198437e-19</td>\n",
       "      <td>1.392154e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.242947e-13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6413</th>\n",
       "      <td>1.565433e-20</td>\n",
       "      <td>1.070934e-07</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.179082e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6414</th>\n",
       "      <td>3.210516e-01</td>\n",
       "      <td>1.968967e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.296464e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6415</th>\n",
       "      <td>5.199302e-01</td>\n",
       "      <td>8.087597e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.133527e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6416</th>\n",
       "      <td>7.090298e-21</td>\n",
       "      <td>1.595068e-08</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.247279e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94978</th>\n",
       "      <td>5.160139e-01</td>\n",
       "      <td>2.189548e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.543263e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94979</th>\n",
       "      <td>4.974943e-01</td>\n",
       "      <td>3.136531e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.575586e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94980</th>\n",
       "      <td>5.368233e-01</td>\n",
       "      <td>3.493056e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.920392e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94981</th>\n",
       "      <td>4.702109e-01</td>\n",
       "      <td>1.151046e-03</td>\n",
       "      <td>0.008000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.645368e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94982</th>\n",
       "      <td>3.974377e-01</td>\n",
       "      <td>9.919689e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.472687e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94983</th>\n",
       "      <td>4.048426e-01</td>\n",
       "      <td>1.329354e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.898969e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94984</th>\n",
       "      <td>5.334305e-01</td>\n",
       "      <td>1.834891e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.132303e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94985</th>\n",
       "      <td>4.051156e-01</td>\n",
       "      <td>1.967320e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.252082e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94986</th>\n",
       "      <td>4.920516e-01</td>\n",
       "      <td>5.597805e-04</td>\n",
       "      <td>0.027987</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.796046e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94987</th>\n",
       "      <td>4.349451e-01</td>\n",
       "      <td>1.533590e-03</td>\n",
       "      <td>0.015000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.400418e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94988</th>\n",
       "      <td>2.869453e-01</td>\n",
       "      <td>4.554067e-03</td>\n",
       "      <td>0.000582</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.473477e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94989</th>\n",
       "      <td>6.052816e-01</td>\n",
       "      <td>1.565787e-05</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.663311e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94990</th>\n",
       "      <td>2.869453e-01</td>\n",
       "      <td>4.554067e-03</td>\n",
       "      <td>0.000582</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.473477e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94991</th>\n",
       "      <td>5.670613e-01</td>\n",
       "      <td>4.658955e-04</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.173469e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94992</th>\n",
       "      <td>7.729418e-01</td>\n",
       "      <td>2.729204e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.996793e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94993</th>\n",
       "      <td>5.084413e-01</td>\n",
       "      <td>3.895635e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.073404e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94994</th>\n",
       "      <td>2.869453e-01</td>\n",
       "      <td>4.554067e-03</td>\n",
       "      <td>0.000582</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.473477e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94995</th>\n",
       "      <td>3.699394e-01</td>\n",
       "      <td>3.327569e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.217713e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94996</th>\n",
       "      <td>4.249525e-01</td>\n",
       "      <td>1.894320e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.281137e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94997</th>\n",
       "      <td>3.705490e-01</td>\n",
       "      <td>2.082017e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.145781e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94998</th>\n",
       "      <td>5.022658e-01</td>\n",
       "      <td>2.513598e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.349033e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94999</th>\n",
       "      <td>3.094518e-01</td>\n",
       "      <td>4.502196e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.738030e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95000</th>\n",
       "      <td>4.397977e-01</td>\n",
       "      <td>1.218237e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.022433e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95001</th>\n",
       "      <td>2.869453e-01</td>\n",
       "      <td>4.554067e-03</td>\n",
       "      <td>0.000582</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.473477e-03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95002</th>\n",
       "      <td>4.572804e-01</td>\n",
       "      <td>9.509719e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.659051e-04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95003</th>\n",
       "      <td>5.022619e-01</td>\n",
       "      <td>9.779336e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.368501e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95004</th>\n",
       "      <td>5.804834e-01</td>\n",
       "      <td>7.171879e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.806704e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95005</th>\n",
       "      <td>3.801239e-01</td>\n",
       "      <td>1.624575e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.927857e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95006</th>\n",
       "      <td>4.486162e-01</td>\n",
       "      <td>1.152464e-03</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.542623e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95007</th>\n",
       "      <td>9.951867e-01</td>\n",
       "      <td>3.688452e-04</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.045810e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>88621 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 NB            LR        RF  SVM            NN\n",
       "6387   3.404842e-01  3.921922e-03  0.000000  0.0  2.472640e-03\n",
       "6388   3.613225e-01  1.070882e-03  0.000000  0.0  6.669514e-04\n",
       "6389   3.809107e-01  2.090709e-04  0.000000  0.0  6.467624e-06\n",
       "6390   3.525849e-01  1.606118e-03  0.000000  0.0  7.360208e-05\n",
       "6391   4.651333e-01  3.153660e-03  0.000000  0.0  4.142533e-03\n",
       "6392   9.754979e-15  2.190598e-06  0.000000  0.0  7.461036e-14\n",
       "6393   4.511036e-15  2.288421e-06  0.000000  0.0  1.438351e-13\n",
       "6394   1.437577e-15  7.475549e-07  0.000000  0.0  2.706684e-15\n",
       "6395   3.162768e-01  2.150531e-03  0.000000  0.0  3.594412e-03\n",
       "6396   3.311566e-01  6.061353e-04  0.000000  0.0  2.814273e-03\n",
       "6397   3.551827e-01  1.564069e-03  0.000000  0.0  1.165430e-03\n",
       "6398   1.264752e-15  4.560757e-06  0.000000  0.0  3.060509e-12\n",
       "6399   5.288710e-16  4.708565e-06  0.000000  0.0  3.530897e-12\n",
       "6400   2.194818e-16  4.880651e-06  0.000000  0.0  3.987091e-12\n",
       "6401   8.932326e-17  5.061068e-06  0.000000  0.0  4.512578e-12\n",
       "6402   3.380293e-17  4.948354e-06  0.010000  0.0  1.302998e-12\n",
       "6403   1.342473e-17  5.188557e-06  0.000000  0.0  1.865801e-12\n",
       "6404   5.219947e-18  5.444968e-06  0.000000  0.0  2.681377e-12\n",
       "6405   1.985910e-18  5.702241e-06  0.000000  0.0  3.697039e-12\n",
       "6406   7.401824e-19  5.973035e-06  0.000000  0.0  4.994347e-12\n",
       "6407   2.701015e-19  6.259274e-06  0.000000  0.0  6.387325e-12\n",
       "6408   4.589283e-01  1.188628e-03  0.000000  0.0  1.437423e-03\n",
       "6409   4.184343e-01  2.814571e-03  0.000000  0.0  2.045322e-03\n",
       "6410   4.466624e-01  3.829563e-04  0.000000  0.0  3.750931e-06\n",
       "6411   4.139319e-01  1.223270e-03  0.000000  0.0  5.136301e-03\n",
       "6412   1.198437e-19  1.392154e-07  0.000000  0.0  2.242947e-13\n",
       "6413   1.565433e-20  1.070934e-07  0.000000  0.0  1.179082e-16\n",
       "6414   3.210516e-01  1.968967e-03  0.000000  0.0  3.296464e-03\n",
       "6415   5.199302e-01  8.087597e-06  0.000000  0.0  2.133527e-06\n",
       "6416   7.090298e-21  1.595068e-08  0.000000  0.0  1.247279e-16\n",
       "...             ...           ...       ...  ...           ...\n",
       "94978  5.160139e-01  2.189548e-03  0.000000  0.0  4.543263e-03\n",
       "94979  4.974943e-01  3.136531e-03  0.000000  0.0  2.575586e-04\n",
       "94980  5.368233e-01  3.493056e-03  0.000000  0.0  4.920392e-04\n",
       "94981  4.702109e-01  1.151046e-03  0.008000  0.0  7.645368e-04\n",
       "94982  3.974377e-01  9.919689e-04  0.000000  0.0  8.472687e-06\n",
       "94983  4.048426e-01  1.329354e-03  0.000000  0.0  3.898969e-05\n",
       "94984  5.334305e-01  1.834891e-04  0.000000  0.0  2.132303e-05\n",
       "94985  4.051156e-01  1.967320e-04  0.000000  0.0  2.252082e-05\n",
       "94986  4.920516e-01  5.597805e-04  0.027987  0.0  2.796046e-03\n",
       "94987  4.349451e-01  1.533590e-03  0.015000  0.0  4.400418e-03\n",
       "94988  2.869453e-01  4.554067e-03  0.000582  0.0  2.473477e-03\n",
       "94989  6.052816e-01  1.565787e-05  0.000000  0.0  4.663311e-03\n",
       "94990  2.869453e-01  4.554067e-03  0.000582  0.0  2.473477e-03\n",
       "94991  5.670613e-01  4.658955e-04  0.003333  0.0  3.173469e-02\n",
       "94992  7.729418e-01  2.729204e-04  0.000000  0.0  5.996793e-04\n",
       "94993  5.084413e-01  3.895635e-03  0.000000  0.0  4.073404e-02\n",
       "94994  2.869453e-01  4.554067e-03  0.000582  0.0  2.473477e-03\n",
       "94995  3.699394e-01  3.327569e-03  0.000000  0.0  4.217713e-05\n",
       "94996  4.249525e-01  1.894320e-03  0.000000  0.0  2.281137e-05\n",
       "94997  3.705490e-01  2.082017e-03  0.000000  0.0  2.145781e-04\n",
       "94998  5.022658e-01  2.513598e-03  0.000000  0.0  3.349033e-04\n",
       "94999  3.094518e-01  4.502196e-03  0.000000  0.0  1.738030e-03\n",
       "95000  4.397977e-01  1.218237e-03  0.000000  0.0  5.022433e-04\n",
       "95001  2.869453e-01  4.554067e-03  0.000582  0.0  2.473477e-03\n",
       "95002  4.572804e-01  9.509719e-04  0.000000  0.0  4.659051e-04\n",
       "95003  5.022619e-01  9.779336e-04  0.000000  0.0  3.368501e-05\n",
       "95004  5.804834e-01  7.171879e-04  0.000000  0.0  4.806704e-05\n",
       "95005  3.801239e-01  1.624575e-04  0.000000  0.0  1.927857e-05\n",
       "95006  4.486162e-01  1.152464e-03  0.000000  0.0  6.542623e-05\n",
       "95007  9.951867e-01  3.688452e-04  0.000000  0.0  1.045810e-01\n",
       "\n",
       "[88621 rows x 5 columns]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "score_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "score_df.to_csv(\"Fraud Scores.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 'data' (DataFrame)\n",
      "Stored 'df' (DataFrame)\n",
      "Stored 'features' (ndarray)\n",
      "Stored 'labels' (Series)\n",
      "Stored 'X_train' (ndarray)\n",
      "Stored 'X_test' (ndarray)\n",
      "Stored 'y_train' (Series)\n",
      "Stored 'y_test' (Series)\n",
      "Stored 'data' (DataFrame)\n",
      "Stored 'NB_features' (list)\n",
      "Stored 'LR_features' (list)\n",
      "Stored 'RF_features' (list)\n",
      "Stored 'SVM_features' (list)\n",
      "Stored 'NN_features' (list)\n"
     ]
    }
   ],
   "source": [
    "# store all the variables for subsequent use\n",
    "%store data\n",
    "%store df\n",
    "%store features\n",
    "%store labels\n",
    "%store X_train\n",
    "%store X_test\n",
    "%store y_train\n",
    "%store y_test\n",
    "%store data\n",
    "%store NB_features\n",
    "%store LR_features\n",
    "%store RF_features\n",
    "%store SVM_features\n",
    "%store NN_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
